<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

 <title>pyVision</title>
 <link href="pi19404.github.io/atom.xml" rel="self"/>
 <link href="pi19404.github.io/"/>
 <updated>2014-10-20T01:24:34+05:30</updated>
 <id>pi19404.github.io</id>
 <author>
   <name>pi19404</name>
   <email>pi19404@gmail.com</email>
 </author>

 
 <entry>
   <title>Time Delay Estimation Techniques - part 2</title>
   <link href="pi19404.github.io/2014/10/19/TODA2/"/>
   <updated>2014-10-19T00:00:00+05:30</updated>
   <id>pi19404.github.io/2014/10/19/TODA2</id>
   <content type="html">&lt;h3&gt;Introduction&lt;/h3&gt;

&lt;p&gt;In this article we will look at improving the Time Delay estimation in presense of noise using information of signals coming in from multiple receivers or observing multiple samples
intervals of the signal.&lt;/p&gt;

&lt;h3&gt;Background&lt;/h3&gt;

&lt;p&gt;Let us consider an array of N receiver ,the signal $x_{m}[n]$ at receiver is given by&lt;/p&gt;

&lt;p&gt;$$ x_{m}[n] = s[n]*h[n]+w[n] $$&lt;/p&gt;

&lt;p&gt;Let us say that by choosing the appropriate  delays $\delta_{m}$ we can make all the receivers aligned in time and them summing the time aligned signals together.&lt;/p&gt;

&lt;p&gt;The aim of such techniques is to boost SNR of the signal by combining the signals from multiple receivers.&lt;/p&gt;

&lt;p&gt;Since the signal is periodic,we can observe multiple instances of the same signal.Again if we are sure that the signals are coherent in sampled intervals we can combine multiple observation of the signal.The aim of such techniques is to boost the SNR of the signal by observing multiple instances of the singal.&lt;/p&gt;

&lt;p&gt;Both techniques have the same effect of enhancing the signal and averaging the noise,therby increasing the SNR of the signal.&lt;/p&gt;

&lt;h3&gt;Reducing Environmental Noise&lt;/h3&gt;

&lt;p&gt;Mathematically this can be expressed as&lt;/p&gt;

&lt;p&gt;$$ y[n] = \sum_{m=1}^{M} x_{m}[n-\delta_{m}] $$&lt;/p&gt;

&lt;p&gt;$$ y[n] = \sum_{m=1}^{M} s_{m}[n-\delta_{m} ] + w_{m}[n] $$&lt;/p&gt;

&lt;p&gt;The noise due to sensor or amplification process can be assumed to be independent.
The noise introduced dues to environment will be same in all the receivers.
The noise can be assumed to be sample of stationary white random process.&lt;/p&gt;

&lt;p&gt;Let us assume for now that signals are time aligned &lt;/p&gt;

&lt;p&gt;We can see that the our signal contains information plus additive noise.Most of region
contains just noise and only a small section of the time duration contains the information.&lt;/p&gt;

&lt;p&gt;The basic idea is that when we add the signals ,information will get enhanced while the noise will get averaged.In this way we can boost signal strength and achieve higher SNR.&lt;/p&gt;

&lt;p&gt;If the noise from independent receivers are considered to uncorrleated.
When we add noise components,we are  effectively adding two independent gaussian
random variables.Thus resultant is also a Gaussian random variable.&lt;/p&gt;

&lt;p&gt;The sum of N Gaussian random variables is the Gaussian random variable with the standard deviation
$$ \sqrt{ \sum_{i=0}^N\sigma_{i }^2}$$&lt;/p&gt;

&lt;p&gt;Thus if we consider that noise power is same in each of receivers then by adding the signals
the resultant noise power is &lt;/p&gt;

&lt;p&gt;$$P_{N}=  \sigma^2 N$$&lt;/p&gt;

&lt;p&gt;However the signal is a deterministic ,the resultant signal power of adding N signals is &lt;/p&gt;

&lt;p&gt;$P_{M} = N^2 P_{S} $&lt;/p&gt;

&lt;p&gt;Thus the SNR of resultant signal is &lt;/p&gt;

&lt;p&gt;$$ SNR = \frac{P_{s}}{P_{n}} N$$&lt;/p&gt;

&lt;p&gt;The SNR is boosted by $N$ times.&lt;/p&gt;

&lt;p&gt;Let us see if we can observe this via simulations&lt;/p&gt;

&lt;p&gt;to generated uncorrelated random sequences,we change the seed every time we generate the random noise.This will simulate condition of noise generated from multiple sensors.&lt;/p&gt;

&lt;p&gt;In the first case we observe only the noise signal&lt;/p&gt;

&lt;p&gt;Let us observe the variance of sum signal for N={2,4,8 .... 128}&lt;/p&gt;

&lt;p&gt;|   |  | |
----|------|----
N | Simulation | Theory
2 | 0.14  | 0.14
4 | 0.20 | 0.2
8 | 0.28  | 0.28
16 | 0.39|0.4
32 | 0.56|0.56
64 | 0.78|0.8
128 | 1.144|1.13&lt;/p&gt;

&lt;p&gt;we can see from the table that simulated and theoretical results agrees with each other&lt;/p&gt;

&lt;p&gt;we consider the case where $M=4$ independent receivers are used .The signal is corrupted by additive environmental  noise of variance $\sigma^2=0.2$ &lt;/p&gt;

&lt;pre &gt;
signal strength 1.6
noise power  0.04
Input SNR  40.0
estimated noise power  0.16
estimated signal power  6.4
estimated SNR  40.0
estimated improvement  1.0
emprical signal power  6.56051311603
emprical noise power  0.160339040093
emprical SNR  40.9165048776
emprical SNR improvement  1.02291262194
&lt;/pre&gt;

&lt;p&gt;The empirical results agree with our theoretical analysis.
Thought the improvement factor is not very significant&lt;/p&gt;

&lt;h3&gt;Sensor Noise&lt;/h3&gt;

&lt;p&gt;The next case comes where we observe signal from the same receiver over N periods.&lt;/p&gt;

&lt;p&gt;Again the noise observed at each sample instance $[n]$ is sample of Gaussian random variable
since we assume stationary noise process.Thus noise variance is $\sigma^2$.Thus the sum signal will have noise power of $(N * \sigma^2)$&lt;/p&gt;

&lt;p&gt;As we add the signals the signal power increases by factor $N^2$.&lt;/p&gt;

&lt;p&gt;This comes directly from central limit theorem and law of larger numbers that the sum of N iid samples will approach gaussian distribution.Thus noise variance will be $\sigma^2$.&lt;/p&gt;

&lt;p&gt;$$ SNR =  \frac{P_{s}}{P_{n}} {N}$$&lt;/p&gt;

&lt;p&gt;The SNR is boosted by N Times.&lt;/p&gt;

&lt;p&gt;we consider the case where $M=2$ independent receivers are observed over a duration of $N=4$ periods.The signal is corrupted by additive  sensor noise of variance $\sigma^2=0.4$  &lt;/p&gt;

&lt;p&gt;let us consider the case of $N=1$ ,number of periods
&lt;pre &gt;
signal strength 1.6
noise power  0.16
Input SNR  10.0
estimated noise power  0.32
estimated signal power  6.4
estimated SNR  20.0
estimated improvement  2.0
emprical signal power  7.04582360211
emprical noise power  0.321264927044
emprical SNR  21.931505773
emprical SNR improvement  2.1931505773
&lt;/pre&gt;
Let us consider the case of $N=4$
&lt;pre &gt;
signal strength 1.6
noise power  0.16
Input SNR  10.0
estimated noise power  1.28
estimated signal power  102.4
estimated SNR  80.0
estimated improvement  8.0
emprical signal power  105.0704936
emprical noise power  1.27294915151
emprical SNR  82.5409981816
emprical SNR improvement  8.25409981816
&lt;/pre&gt;&lt;/p&gt;

&lt;p&gt;The empirical estimates again agree with our theoretical analysis.
We get a significant improvement in SNR,just by increasing the number of periods of observation.The SNR improves linearly by factor of $N$.&lt;/p&gt;

&lt;h3&gt;SNR Improvement In Presence of sensor and environmental noise&lt;/h3&gt;

&lt;p&gt;Let us say that the signal is corrupted by both environmental and receiver noise&lt;/p&gt;

&lt;p&gt;There are  N receivers .The same environmental noise is observed in each of the receivers.
Let us assume that the sequences are time aligned.Each of receivers has uncorrelated noise components.
We observe each receiver channel for M periods .&lt;/p&gt;

&lt;p&gt;Thus in total we have M*N Signals&lt;/p&gt;

&lt;p&gt;Thus total noise power in a single period be considered as $2 \sigma^2$&lt;/p&gt;

&lt;p&gt;The environmental noise component which is present in all the sensors cannot
be reduced by adding the sensor signals.This component can only be reduced by observing the signal over longer duration&lt;/p&gt;

&lt;p&gt;When signals from different receivers are added,the environmental noise power is also amplified
along with the signal.This noise power is amplified by a factor $N^2$&lt;/p&gt;

&lt;p&gt;Now we have M periods of the signal,Thus noise power after adding M periods of the signal is given by
$M*N^2$.&lt;/p&gt;

&lt;p&gt;The factor by which total sensor noise power increases by adding all the signals is given by $MN$&lt;/p&gt;

&lt;p&gt;Thus the total noise power is given by $M N^2 \sigma_{1}^2 + MN \sigma_{2}^2$&lt;/p&gt;

&lt;p&gt;The factor by which total signal power increases by adding all the signals is given by $M^2N^2$&lt;/p&gt;

&lt;p&gt;Thus SNR of sum of signals is given by $\frac{M^2N^2 P_{M}}{M N^2 \sigma_{1}^2 + MN \sigma_{2}^2}$&lt;/p&gt;

&lt;p&gt;When both variances are same,the SNR Improvement can be expressed as 
$\frac{2M^2N^2}{N^2M+NM} =\frac {2MN}{N+1}$&lt;/p&gt;

&lt;p&gt;we consider the case where $N=2$ independent receivers are observed over a duration of $M=4$ periods.The signal is corrupted by additive  environmental and sensor noise of variance $\sigma^2=0.4$  &lt;/p&gt;

&lt;p&gt;Theoretical improvement by a factor of   5.33&lt;/p&gt;

&lt;pre&gt;
signal strength 1.6
noise power  0.32
Input SNR  5.0
estimated noise power  3.84
estimated signal power  102.4
estimated SNR  26.6666666667
estimated improvement  5.33333333333
emprical signal power  107.678534403
emprical noise power  3.82682954561
emprical SNR  28.1377921644
emprical SNR improvement  5.62755843289
&lt;/pre&gt;

&lt;p&gt;The simulations give a improvement by 5.62&lt;/p&gt;

&lt;p&gt;In terms of decibles its improvement of about 25db just by averaging signals.&lt;/p&gt;

&lt;p&gt;Also it can be seen that improvement is larger by considering longer duration signals than adding more receivers.&lt;/p&gt;

&lt;h3&gt;Time Delay Estimation&lt;/h3&gt;

&lt;p&gt;Given signals form  the receviers,time period to analyze signals we compute the SNR for all possible delays between the signals.The delay which gives the maximum SNR is considered to be the time delay between the signals.&lt;/p&gt;

&lt;p&gt;In the present article we only consider pairs of signals for analysis.We can perform the delay and sum operation wrt to ideal signal or noisy signal from one of the receivers.&lt;/p&gt;

&lt;h3&gt;Ideal Signal&lt;/h3&gt;

&lt;p&gt;In the first method we  construct an ideal signal and perform this computation wrt signals obtained from both the receivers.&lt;/p&gt;

&lt;p&gt;The ideal signal is not plagued by environmental and sensor noise.When we add ideal and noisy version of the signal,the environmental and sensor noise are averaged.&lt;/p&gt;

&lt;p&gt;However the improvement is only between a pair of signals.The environmental signal can only be reduced by a factor of 4.&lt;/p&gt;

&lt;p&gt;Let us first consider the case of noise variance of $0.4$ and use a ideal signal to perform the computation&lt;/p&gt;

&lt;pre&gt;
signal strength 1.6
noise power  0.32
Input SNR  5.0
estimated noise power  1.28
estimated signal power  102.4
estimated SNR  80.0
estimated improvement  16.0
emprical signal power  103.442427564
emprical noise power  1.26823592579
emprical SNR  81.5640256366
emprical SNR improvement  16.3128051273
mean delay  5.0
std deviation  0.0
&lt;/pre&gt;

&lt;p&gt;Now the same computation is performed using a signal received from one of the receivers.
$MN^2 \sigma_{1}^2 + MN \sigma_{2}^2$ and for N=2 we get $4M  \sigma_{1}^2 + 2M \sigma_{2}^2$
and the total signal power increases by $4 M^2$&lt;/p&gt;

&lt;pre&gt;
signal strength 1.6
noise power  0.32
Input SNR  5.0
estimated noise power  3.84
estimated signal power  102.4
estimated SNR  26.6666666667
estimated improvement  5.33333333333
emprical signal power  104.34546039
emprical noise power  3.07193469288
emprical SNR  33.9673433265
emprical SNR improvement  6.79346866529
mean delay  5.0
std deviation  0.0
&lt;/pre&gt;

&lt;p&gt;Improvement factor is greater is the case of using ideal signal.In both the methods
since pairwise operations are performed,increasing the number of receivers has not effect
on the analysis.&lt;/p&gt;

&lt;h3&gt;Code&lt;/h3&gt;

&lt;p&gt;A class  &lt;strong&gt;&lt;em&gt;TimeDelaySimulator&lt;/em&gt;&lt;/strong&gt; encapsulates all the methods for generating time delayed signals with additive environmental and sensor noise components and computing the statistics.&lt;/p&gt;

&lt;p&gt;All the results mentioned in the article can be simulate by executing the script.&lt;/p&gt;

&lt;pre class=&quot;brush:python&quot;&gt;

    def run(self,isignal):
        &quot;&quot;&quot; main function that generates noisy,time delayed signals 
        
        Parameters 
        --------
        isignal : numpy array
                  ideal signal
        Returns
        -------
        out : numpy array shape=(length,channel,period)
            
        
        &quot;&quot;&quot;

        l=len(isignal)
        #array for storing signal and noise
        signal=numpy.zeros((l,self.nchannels,self.periods));
        noise=numpy.zeros((l,self.nchannels,self.periods));    
        
        #generate environmental noise for each period and across all channels
        for k in range(self.periods):
            n=self.GenerateNoise(self.enoise,l)           
            #simulating environmental noise
            for i in range(self.nchannels):
                noise[:,i,k]=n;
            
            
        #for each channel add sensor noise
        for k in range(self.nchannels):
            
            #dummpy call to change the random seed 
            #so that we can generate uncorrelated sensor noise
            self.GenerateNoise(self.snoise,l,1)
            for i in range(self.periods):
                signal[:,k,i]=self.delay(isignal,(k+1)*self.tdelay)+noise[:,k,i]+self.GenerateNoise(self.snoise,l)    
        
        #change the seed everytime the function is called
        self.seed=int(np.random.uniform(0,1)*10000);   
            
        #flag to print the statistics 
        if self.once==1:
            self.once=0;
            PS=np.mean(isignal*isignal);
            PN=self.enoise*self.enoise+self.snoise*self.snoise;
           
            if self.tde_method==0:
                PNT=(self.periods*self.enoise*self.enoise)
                PNT=PNT+(self.periods*self.nchannels*self.snoise*self.snoise/self.nchannels)
                PST=(self.periods*self.periods)*PS*4              
                
            if self.tde_method==1:
                PNT=(self.periods*4*self.enoise*self.enoise)
                PNT=PNT+(self.periods*2*self.snoise*self.snoise)
                PST=(self.periods*self.periods)*PS*4
            
            print &quot;signal strength&quot;,PS
            print &quot;noise power &quot;,PN
            self.SNRI=PS/PN
            print &quot;Input SNR &quot;,self.SNRI          
            print &quot;estimated noise power &quot;,PNT
            print &quot;estimated signal power &quot;,PST
            self.SNR0=PST/PNT
            print &quot;estimated SNR &quot;,self.SNR0
            print &quot;estimated improvement &quot;,self.SNR0/self.SNRI
        
        #returns the signal        
        return signal

&lt;/pre&gt;

&lt;p&gt;A class  &lt;strong&gt;&lt;em&gt;TimeDelayEstimator&lt;/em&gt;&lt;/strong&gt; encapsulates all the methods for computing the time delay estimation mentioned in the article.&lt;/p&gt;

&lt;pre class=&quot;brush:python&quot;&gt;

    def run(self,signal,isignal,enoise,snoise,method=0):
        &quot;&quot;&quot; the main function that performs time delay estimation
        
        Parameters
        -----------
        signal : numpy array shape=(length,channel,periods)
                 input noisy signals for time delay estimation
                 
        isgignal : numpy array shape=(length,)
                   ideal signal
                   
        enoise,snoise : float 
                        environmental and sensor noise standard deviation
        
        method      : integer
                      0 - for pariwise delay sum with ideal signal
                      1 - pariwise delay sum with noisy signals
        
        Returns
        -------
        tdelay : numpy integer
                 estimated time delay
             
        
        &quot;&quot;&quot;
        
        size1=signal.shape;
        ch=size1[1];
        length=size1[0];
        periods=size1[2];
        enoise=enoise*enoise;
        snoise=snoise*snoise;
        PS=np.mean(isignal*isignal);      
 


        if method==0:
            iloop=ch-1
        if method==1:
            iloop=ch-1;         
        
        #compute the SNR threshold
        if method==0:
            vnoise=(periods**enoise/4)+(periods*iloop*snoise/iloop);
            vsnoise=[-2*vnoise,2*vnoise]    
            ispower=(periods*periods*PS);
            spower=np.mean(signal*signal)*periods*periods
            OSNR=(periods*periods*4*PS)+(1*vsnoise);
            OSNR=OSNR/(periods*periods)
        if method==1:
            vnoise=(periods*enoise)+(periods*iloop*snoise);
            vsnoise=[-2*vnoise,1*vnoise];
            spower=np.mean(signal*signal)*periods*periods
            ispower=(periods*periods*iloop*iloop*PS);
            OSNR=(periods*periods*4*PS)+vsnoise
            OSNR=OSNR/(periods*periods)
           
        
        
        #add the signals along periods
        s=np.mean(signal,axis=2);
        
  
        SNR=np.zeros((iloop,length))
        for i in range(iloop):
            #delay sum operation for various delays
            for k in range(length):
                if method==0:
                
                    su=s[:,0]+self.delay(s[:,i+1],k)
                if method==1:
                    su=s[:,0]+self.delay(s[:,i+1],k)
                
                #apply SNR Thresholding
                SNR[i,k]=np.mean(su*su);
                if(SNR[i,k] &amp;lt ;OSNR[0]):
                   SNR[i,k]=0
        
        #find the index of maximum SNR
        m1=np.argmax(SNR,axis=1)          
   

        #average all the time delays        
        if method==0:
            tdelay=0;
            
            
            for i in range(iloop-1):
               
                tdelay=tdelay+abs(m1[0]-m1[i+1])/(i+1)
            tdelay=tdelay/(iloop-1)
        if method==1:
            
            tdelay=0;
            for i in range(iloop):
                tdelay=tdelay+((length-(abs(m1[i])+1)))/(i+1);
              
            
            tdelay=tdelay/iloop;
           
            

        #return the result  
        return tdelay   

&lt;/pre&gt;

&lt;p&gt;Change the mode from 0-4 to test various algorithms.The parameters like delay and noise can also
be changed and the various results mentioned in the article can be generated.&lt;/p&gt;

&lt;p&gt;The code can be found in the pyVision github repository &lt;a href=&quot;https://github.com/pi19404/pyVision&quot;&gt;https://github.com/pi19404/pyVision&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Files&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;pySignalProc/TimeDelayEstimation.py&lt;/li&gt;
&lt;/ul&gt;
</content>
 </entry>
 
 <entry>
   <title>Time Delay Estimation Techniques - Part 1</title>
   <link href="pi19404.github.io/2014/10/13/TDOA1/"/>
   <updated>2014-10-13T00:00:00+05:30</updated>
   <id>pi19404.github.io/2014/10/13/TDOA1</id>
   <content type="html">&lt;h3&gt;Introduction&lt;/h3&gt;

&lt;p&gt;In this article we will look at signal processing techniques for time delay estimation.&lt;/p&gt;

&lt;h3&gt;Background&lt;/h3&gt;

&lt;p&gt;Time delay estimation has been a research topic of significant practical importance in
many fields like radar, sonar, seismology, geophysics, ultrasonic&amp;#39;s, hands-free communications,Doppler positioning systems etc and is of fundamental importance in a variety of signal-processing applications.&lt;/p&gt;

&lt;p&gt;The problem boils down to computing the location of a digitized &amp;quot;signature&amp;quot; waveform residing within a larger time-slice.&lt;/p&gt;

&lt;p&gt;Let $s(n)$ be the sound source signal.
Let us consider two  spatially separated sensors and $x_{1}(t)$ and $x_{2}(t)$ be result of propagation of $s(t)$ through different paths to reach the respective sensors.&lt;/p&gt;

&lt;p&gt;A simple propagation model is that the signals just encounter attenuation and delay and are corrupted by additive noise&lt;/p&gt;

&lt;p&gt;$x_{i}(t) =  a_{i} s(t- \tau_{i}) + b_{i}(t)$&lt;/p&gt;

&lt;p&gt;where ,&lt;/p&gt;

&lt;p&gt;$b_{i}(t)$ is the additive noise uncorrelated with the signal&lt;/p&gt;

&lt;p&gt;We make a assumption that the distance from the sensors to the source is very large compared to the spatial separation between the sensors.Thus signal $s(t)$ received by both the receivers is the same,there is no significant change in the signal as it travels thorough different paths to reach the spatially separated sensors.&lt;/p&gt;

&lt;h3&gt;Cross-correlation&lt;/h3&gt;

&lt;p&gt;One of the simplest method of time delay estimation is cross-correlation .
The cross-correlation of two signals is a measure of similarity between the two sequences.
The cross-correlation function is maximized when both the signals have significant overlap.&lt;/p&gt;

&lt;p&gt;$R_{xy}(k) = \sum_{i} {x(i) y(i+k)} = x[n]*y[-n]$&lt;/p&gt;

&lt;p&gt;Compute maximum absolute value of the correlation function to estimate the lag.&lt;/p&gt;

&lt;p&gt;To test the results we create  create two sequences,one a delayed version of another.
We add white noise to the delayed sequence and use sample correlation to detect the lag.
while performing correlation we normalize the signals,so that correlation measure is bounded
between [0,1]&lt;/p&gt;

&lt;p&gt;Now we increase the noise to try to get estimate of noise co-variance at which this technique fails.
we run the experiment 100 times and estimate the number of times we get the proper answer.&lt;/p&gt;

&lt;h4&gt;Testing with Different Additive Noise Covariance&lt;/h4&gt;

&lt;pre class=&quot;brush : python &quot;&gt;
 *********** Information ************ 
time delay :  10
Noise : 0.1
SNR 15.4390474505
Correct  98  Incorrect  3
mean  9.90099009901 Std  1.0000490136
&lt;/pre&gt;

&lt;p&gt;We see that we are always correct,when the noise levels are low or SNR is high&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://googledrive.com/host/0B-pfqaQBbAAtbExWN0Zya3JySzA/image9.png&quot; alt=&quot;enter image description here&quot;&gt;&lt;/p&gt;

&lt;pre class=&quot;brush : python &quot;&gt;
 *********** Information ************ 
time delay :  10
Noise : 0.3
SNR 5.89662235611
Correct  48  Incorrect  53
mean  9.79207920792 Std  1.2767287382
&lt;/pre&gt;

&lt;p&gt;The SNR has dropped to about 6db and error in estimation is about 50%. The accuracy is linearly
related with the SNR&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://googledrive.com/host/0B-pfqaQBbAAtbExWN0Zya3JySzA/image10.png&quot; alt=&quot;enter image description here&quot;&gt;&lt;/p&gt;

&lt;pre class=&quot;brush : python &quot;&gt;
 *********** Information ************ 
time delay :  10
Noise : 0.5
SNR 1.45964736379
Correct  36  Incorrect  65
mean  9.80198019802 Std  1.57969668714

&lt;/pre&gt;

&lt;p&gt;At 2 db SNR we can see the variance of estimated time delay increasing with rising noise levels.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://googledrive.com/host/0B-pfqaQBbAAtbExWN0Zya3JySzA/image11.png&quot; alt=&quot;enter image description here&quot;&gt;&lt;/p&gt;

&lt;p&gt;We can see in the auto-correlation plot the difference between the peak and its neighbors is not significant and depending on the random noise levels introduced,we may not always get the right answer.&lt;/p&gt;

&lt;p&gt;As noise increases,we can see variance in the estimated time delay increases and error in estimation also increases.As the level of noise increases, the uncertainty in the time-delay estimate increases&lt;/p&gt;

&lt;p&gt;We need a reliable time delay estimator in presence of additive noise.&lt;/p&gt;

&lt;p&gt;If is always difficult to estimate the time delays for a base-band signal illustrated above.The due to the noise,we are not reliably able to estimate the delay corresponding to the maximal overlap between the noisy and ideal signal.&lt;/p&gt;

&lt;pre class=&quot;brush:python&quot;&gt;
def delay(signal,N):
    &quot;&quot;&quot; function introduces a delay of N samples 
    
    Parameters
    -----------
    signal : numpy-array,
             The input signal
             
    N      : integer
             delay
        
    Returns
    --------
    out : numpy-array
          delayed signal
    
    &quot;&quot;&quot;
    d=numpy.zeros((1,N+1));    
    signal=numpy.append(d,signal)
    return signal;

def addNoise(s,variance):
    &quot;&quot;&quot; function add additive white gaussian noise to the input signal 
    
    Parameters
    -----------
    s : numpy-array,
             The input signal
             
    N      : float
             noise covariance
        
    Returns
    --------
    out : numpy-array
          noisy signal    
    
    &quot;&quot;&quot;
    noise = np.random.normal(0,variance,len(s))                    
    s=s+noise;                              
    return s;


if __name__ == &quot;__main__&quot;:  
            
        Fs=1000;
        
        mode=0
        if mode==0:
            x = triang(20);
            x2=x;

        ......
            
        tdelay=10;
        varnoise=0.001;
        loop=1000

        
        #delay the signal
        dx=delay(x,tdelay);
        result=numpy.zeros((1,loop));
        for i in range(loop):
            s=dx;
            #add noise
            s=addNoise(s,varnoise);
            
            #normalize the signals
            s=s/np.linalg.norm(s);
            x1=x2/np.linalg.norm(x2);
            
            unfiltered_signal=s;
            
            r=numpy.correlate(s,x1,mode=&quot;full&quot;)
            arg=np.argmax(r)
            result[0,i]=abs(arg-len(x))     

        #plot the results
        c=np.sum(result==tdelay)
        ic=np.sum(result!=tdelay)
        #10*np.log(np.sum(np.abs(x*x))/
        print &quot; *********** Information ************ &quot;
        print 'time delay : ',tdelay
        print 'Noise :',varnoise
        print &quot;SNR&quot;,10*np.log(np.mean(abs(x*x))/(varnoise*varnoise))/np.log(10);
        print &quot;Correct &quot;,str(c),&quot; Incorrect &quot;,str(ic)
        print &quot;mean &quot;,np.mean(result),&quot;Std &quot;,np.std(result)
        print result
        plt.figure(1)
        subplot(2,2,1) 
        plt.plot(range(len(x)),x)
        xlabel('Time')
        ylabel('Amplitude')

        
        subplot(2,2,2) 
        plt.plot(range(len(unfiltered_signal)),unfiltered_signal)
        xlabel('Time')
        ylabel('Amplitude')

        subplot(2,2,3) 
        plt.plot(range(len(r)),r)
        xlabel('Time')
        ylabel('Amplitude')            
&lt;/pre&gt;
    

&lt;h3&gt;Rectangular Pulse signals&lt;/h3&gt;

&lt;p&gt;Let us look at the results for a different signal in the form of a rectangular pulse .
we will consider the wave of same duration 30.&lt;/p&gt;

&lt;pre class=&quot;brush : python &quot;&gt;
 *********** Information ************ 
time delay :  10
Noise : 0.5
SNR 0.791812460476
Correct  86  Incorrect  15
mean  9.92079207921 Std  1.11411438271
&lt;/pre&gt;

&lt;p&gt;we see that signal has a lower SNR,but accuracy and estimated time delay variance is lower.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://googledrive.com/host/0B-pfqaQBbAAtbExWN0Zya3JySzA/image12.png&quot; alt=&quot;enter image description here&quot;&gt;
Thus the type of pulse we use has a impact on the accuracy of auto-correlation function.&lt;/p&gt;

&lt;pre class=&quot;brush:python&quot;&gt;
def rectangular(N,start,end):
        &quot;&quot;&quot; fuction generates a rectangular pulse 
        
        Parameters
        ---------
        N : integer
            length of signal
            
        start,end: integer
                starting and ending index of pulse
        
        &quot;&quot;&quot;
        x = np.zeros((1,N))
        x[:,start:end]=1;
        x=x.flatten();    
        return x;
 &lt;/pre&gt;
 
### Coded Pulses 
Broadband  techniques have a sequence of code pulses that increase the accuracy of time delay estimation in the presence of noise.

&lt;pre class=&quot;brush : python &quot;&gt;
time delay :  10
Noise : 0.5
SNR 2.55272505103
Correct  95  Incorrect  6
mean  9.93069306931 Std  1.01725144864

&lt;/pre&gt;

&lt;p&gt;&lt;img src=&quot;https://googledrive.com/host/0B-pfqaQBbAAtbExWN0Zya3JySzA/image13.png&quot; alt=&quot;enter image description here&quot;&gt;&lt;/p&gt;

&lt;pre class=&quot;brush:python&quot;&gt;
x=rectangular(20,8,14)+rectangular(20,2,5)
&lt;/pre&gt;

&lt;p&gt;But most of the time we do not have control of the source pulse.&lt;/p&gt;

&lt;p&gt;In the remainder of the article we will assume that it is a rectangular pulse of duration 1000
with impulse of duration 50 starting at 100.
&lt;pre class=&quot;brush : python &quot;&gt;
time delay :  10
Noise : 0.5
SNR -6.98970004336
Correct  856  Incorrect  144
mean  9.991 Std  0.561176442841
&lt;/pre&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://googledrive.com/host/0B-pfqaQBbAAtbExWN0Zya3JySzA/image14.png&quot; alt=&quot;enter image description here&quot;&gt;&lt;/p&gt;

&lt;pre class=&quot;brush:python&quot;&gt;
x=rectangular(1000,100,150)
&lt;/pre&gt;

&lt;p&gt;Now given source signal,we need to see if we can do better in the presence of additive noise atleast.In real life situations there will be a host of other distortions and effects which will  increase the estimation errors apart from noise.&lt;/p&gt;

&lt;p&gt;For pulses like the ones observed above,noise is a dominant factor,signal energy is low compared to noise energy.&lt;/p&gt;

&lt;h3&gt;Modulated Pulses&lt;/h3&gt;

&lt;p&gt;Often the pulses are modulated by sinusoidal waves for longer range transmissions.
&lt;/pre&gt;
time delay :  10
Noise : 0.5
SNR -6.98970004336
Correct  988  Incorrect  12
mean  10.004 Std  0.109471457467
Actual time delay 10
&lt;/pre&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://googledrive.com/host/0B-pfqaQBbAAtbExWN0Zya3JySzA/image15.png&quot; alt=&quot;enter image description here&quot;&gt;&lt;/p&gt;

&lt;pre class=&quot;brush:python&quot;&gt;
def sinepulse(N,start,end,f,Fs=1000,tau=0):
        &quot;&quot;&quot; function generates modulated rectangular pulse

        Parameters
        ---------
        N : integer
            length of signal
            
        start,end: integer
                starting and ending index of pulse
                
        f   : integer
              modulated carrier freuency
              
        Fs  : integer
              Sampling freuency

        tau : integer
              carrier phase delay in samples.
              
        Returns
        --------
        out : numpy-array
              modulated rectangular  signal               
          
        &quot;&quot;&quot;
        x = np.zeros((1,N))
        t=np.asarray(range(0,end-start));
        x[:,start:end]=np.cos(2*np.pi*f*(t+tau)/Fs);
        
        return x.flatten();
&lt;/pre&gt;

&lt;h3&gt;Carrier Synchronization Issues&lt;/h3&gt;

&lt;p&gt;we can synchronize exactly with the carrier ,then like broadband techniques we can achieve a significantly enhanced SNR. However synchronizations are never possible.&lt;/p&gt;

&lt;p&gt;we introduce a phase delay of 1 sample to check the effect of carrier phase errors
&lt;pre class=&quot;brush : python &quot;&gt;
*********** Information ************ 
time delay :  10
Noise : 0.3
SNR -2.55272505103
Correct  2  Incorrect  998
mean  229.036 Std  244.973840857&lt;/p&gt;

&lt;p&gt;&lt;/pre&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://googledrive.com/host/0B-pfqaQBbAAtbExWN0Zya3JySzA/image16.png&quot; alt=&quot;enter image description here&quot;&gt;&lt;/p&gt;

&lt;p&gt;In such cases another approach might be to use rectangular envelope
but in the present case that also does not seem to help&lt;/p&gt;

&lt;pre class=&quot;brush : python &quot;&gt;
 *********** Information ************ 
time delay :  10
Noise : 0.3
SNR -2.55272505103
Correct  0  Incorrect  1000
mean  325.336 Std  272.058543523

&lt;/pre&gt;

&lt;h4&gt;Envelope Detection&lt;/h4&gt;

&lt;p&gt;We perform envelope detection on the signal and then apply correlation.
This improves the situation considerably&lt;/p&gt;

&lt;pre class=&quot;brush : python &quot;&gt;
 *********** Information ************ 
time delay :  10
Noise : 0.3
SNR -2.55272505103
Correct  661  Incorrect  339
mean  9.746 Std  0.793400277288
&lt;/pre&gt;

&lt;p&gt;&lt;img src=&quot;https://googledrive.com/host/0B-pfqaQBbAAtbExWN0Zya3JySzA/image17.png&quot; alt=&quot;enter image description here&quot;&gt;&lt;/p&gt;

&lt;pre class=&quot;brush : python &quot;&gt;
            if mode==5 or mode ==6 or mode==7:                
                s=abs(scipy.signal.hilbert(s))
&lt;/pre&gt;

&lt;h3&gt;Filtering&lt;/h3&gt;

&lt;p&gt;If we known the carrier frequency ,we can filter the noise outside the signal  bandwidth before performing the correlation operation.&lt;/p&gt;

&lt;p&gt;For the remaining examples we consider signal with carrier frequency of 1KHz and Sampling rate
of 5Khz. The reason for that is explained below&lt;/p&gt;

&lt;p&gt;Let us first look at the frequency characteristics of the rectangular pulse&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://googledrive.com/host/0B-pfqaQBbAAtbExWN0Zya3JySzA/image26.png&quot; alt=&quot;enter image description here&quot;&gt;&lt;/p&gt;

&lt;p&gt;The sharp transition at the edges of the rectangular pulse give rise to high frequency components.
Thus while filtering we need to take these into account,else we may end up distorting the edge
leading to errors in time delay estimation.&lt;/p&gt;

&lt;p&gt;The width of the mainlobe in frequency domain is inversely proportional to width of rectangular pulse
in the time domain.Thus a wider pulse in the time domain will provide higher spectral compression in the frequency domain.&lt;/p&gt;

&lt;p&gt;we can see that main lobe of the rectangular pulse would have normalize freuency of 0.05
Few of the side lobes also contain significant information.&lt;/p&gt;

&lt;pre class=&quot;brush:python&quot;&gt;

def plotFrequency(b,a=1):
    &quot;&quot;&quot; the function plots the frequency and phase response &quot;&quot;&quot;
    w,h = signal.freqz(b,a)
    h_dB = abs(h);#20 * np.log(abs(h))/np.log(10)
    subplot(211)
    plot(w/max(w),h_dB)
    #plt.ylim(-150, 5)
    ylabel('Magnitude (db)')
    xlabel(r'Normalized Frequency (x$\pi$rad/sample)')
    title(r'Frequency response')
    subplot(212)
    h_Phase = np.unwrap(np.arctan2(np.imag(h),np.real(h)))
    plot(w/max(w),h_Phase)
    ylabel('Phase (radians)')
    xlabel(r'Normalized Frequency (x$\pi$rad/sample)')
    title(r'Phase response')
    plt.subplots_adjust(hspace=0.5)
&lt;/pre&gt;    

&lt;p&gt;We try with a normalized frequency components of 0.05 which contains around 3 adjacent side-lobes&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://googledrive.com/host/0B-pfqaQBbAAtbExWN0Zya3JySzA/image31.png&quot; alt=&quot;enter image description here&quot;&gt;&lt;/p&gt;

&lt;p&gt;we can see that the signal has been attenuated near the edges.Thus the distortion in the region where the pulse starts will lead  to ambiguity of time delay computation.&lt;/p&gt;

&lt;p&gt;Thus we need to consider the freuency components to retain so that sharp transition in time domain are not affected&lt;/p&gt;

&lt;p&gt;The carrier freuency is 1Khz .The normalized carrier frequency at sampling rate of 5Khz is 0.4.
Thus the spectrum of modulated rectangular pulse is centered at 0.4&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://googledrive.com/host/0B-pfqaQBbAAtbExWN0Zya3JySzA/image30.png&quot; alt=&quot;enter image description here&quot;&gt;&lt;/p&gt;

&lt;p&gt;Thus significant frequency band lies from 0.3 to 0.5.&lt;/p&gt;

&lt;p&gt;If we bandpass filter frequencies in this band,we should get a relatively noiseless waveform,which is expected to improve the performance of correlation.&lt;/p&gt;

&lt;p&gt;We apply band-pass  butter worth filter of order 2 with normalized cutoff frequencies are 0.2 and 0.6.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://googledrive.com/host/0B-pfqaQBbAAtbExWN0Zya3JySzA/image33.png&quot; alt=&quot;enter image description here&quot;&gt;&lt;/p&gt;

&lt;pre class=&quot;brush:python&quot;&gt;
def butter_bandpass(lowcut, highcut, fs, order=5):
    &quot;&quot;&quot; function returns the bandpass butterworth filter coefficients 
    
    Parameters
    -------------    
    lowcut,highcut : integer
                     lower and higher cutoff freuencies in Hz
                     
    Fs : Integer
         Samping freuency in Hz

    order : Integer
            Order of butterworth filter                     
        
    Returns
    --------
    b,a - numpy-array
          filter coefficients 
          
    &quot;&quot;&quot;
    nyq = 0.5 * fs
    low = lowcut / nyq
    high = highcut / nyq
    b, a = butter(order, [low,high], btype='bandpass')
    return b, a
    
    
def bandpass_filter(data, lowcut, highcut, fs, order,filter_type='butter_worth'):

 &quot;&quot;&quot; the function performs bandpass filtering 
    
    Parameters
    -------------
    data : numpy-array
           input signal
           
    lowcut,highcut : integer
                     lower and higher cutoff freuencies in Hz
                     
    Fs : Integer
         Samping freuency in Hz

    order : Integer
            Order of butterworth filter                     
        
    Returns
    --------
    out : numpy-array
          Filtered signal
    
    &quot;&quot;&quot;
    global once
    if filter_type=='butter_worth':
        b, a = butter_bandpass(lowcut, highcut, fs, order=order)            
        if once==0:
            plt.figure(2)
            plotFrequency(b,a)
            once=1
        y = filtfilt(b, a, data)
        return y
    
&lt;/pre&gt;    

&lt;p&gt;The butter-worth band-pass filter is not a zero phase .It will introduce different phase delay depending of frequency. The.The phase plot of the band pass filter is not linear,&lt;/p&gt;

&lt;p&gt;To see the phase delay effects of bandpass butter-worth filter,we consider the case of no noise .
we can see that instead of 10,delay is introduced as 12 due to butter-worth filter. However we have a stable singular correlation peak being detected&lt;/p&gt;

&lt;pre class=&quot;brush : python &quot;&gt;
 *********** Information ************ 
time delay :  10
Noise : 0.001
SNR 46.9897000434
Correct  0  Incorrect  1000
mean  12.0 Std  0.0
&lt;/pre&gt;

&lt;p&gt;&lt;img src=&quot;https://googledrive.com/host/0B-pfqaQBbAAtbExWN0Zya3JySzA/image34.png&quot; alt=&quot;enter image description here&quot;&gt;&lt;/p&gt;

&lt;pre class=&quot;brush:python&quot;&gt;
.....
        #introduce delay
        dx=delay(x,tdelay);
        result=numpy.zeros((1,loop));
        for i in range(loop):
            s=dx;

            #add noise            
            if varnoise!=0:
                s=addNoise(s,varnoise)

            #normalize signals                
            s=s/np.linalg.norm(s);
            x1=x2/np.linalg.norm(x2);
            if carrier!=None:
                unfiltered_signal=s;
                if mode==1:
                    s = bandpass_filter(s, carrier-500, carrier+500, Fs,order,filter_type)
                if mode==2:
                    s = bandpass_filter(s, carrier-750, carrier+750, Fs,order,filter_type)

                filtered_signal=s;
            else:
                unfiltered_signal=s;
             
            #perform envelope detection
            s=abs(scipy.signal.hilbert(s))
            if mode==1 or mode==2:
                r=numpy.correlate(s,x1,mode=&quot;full&quot;)

.......
&lt;/pre&gt;                

&lt;p&gt;To compensate for that we need to use zero phase filtering techniques like forward backward filtering.&lt;/p&gt;

&lt;p&gt;To achieve zero phase the linear filter is applied twice, once forward and once backwards. The combined filter has zero phase.In general  forward-backward filtering squares the amplitude response and zeros the phase response if phase of filter is linear.&lt;/p&gt;

&lt;p&gt;we see that there are few errors inspire of applying the forward backward algorithm due to distortions introduced by bandpass filtering of high frequency components.Though the mean is closer to actual delay of 10.&lt;/p&gt;

&lt;pre class=&quot;brush : python &quot;&gt;
 *********** Information ************ 
time delay :  10
Noise : 0
Correct  0  Incorrect  1000
mean  9.0 Std  0.0
&lt;/pre&gt;

&lt;p&gt;This tells us that we cannot eliminate the effects introduced due to filtering.&lt;/p&gt;

&lt;p&gt;we now introduce noise and compare the performance against envelope detection.
&lt;pre class=&quot;brush : python &quot;&gt;
 *********** Information ************ 
time delay :  10
Noise : 0.3
SNR -2.55272505103
Correct  442  Incorrect  558
mean  9.49 Std  0.678159273327
&lt;/pre&gt;
&lt;pre class=&quot;brush : python &quot;&gt;
 *********** Envelope Detection ************ 
time delay :  10
Noise : 0.3
SNR -2.55272505103
Correct  661  Incorrect  339
mean  9.746 Std  0.793400277288
&lt;/pre&gt;&lt;/p&gt;

&lt;p&gt;Compared to just envelope detection,we can see that standard deviation has reduced.Thus the neighborhood of estimated TDOA values are reduced,though the mean is shifted away from 10 may be due to the phase delay effects of bandpass filter.&lt;/p&gt;

&lt;p&gt;Though band-pass filtering did not lead to a significant improvement  due no the noise within the frequency bandwidth .It is essential to keep out unwanted frequency components due to environmental noise and other factors.&lt;/p&gt;

&lt;h3&gt;Code&lt;/h3&gt;

&lt;p&gt;The code used in the article can be found in github repository &lt;a href=&quot;https://github.com/pi19404/pyVision/tree/master/pySignalProc&quot;&gt;&amp;quot;Github Link&amp;quot;&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Files &lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;TDOA1.py&lt;/li&gt;
&lt;li&gt;TODA2.py - Band Pass Filtering &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;All the plots included in the article can generated by changing the mode variable in the files&lt;/p&gt;
</content>
 </entry>
 
 <entry>
   <title>Discrete Fourier Transform For Freuency Analysis</title>
   <link href="pi19404.github.io/2014/10/11/DFT1/"/>
   <updated>2014-10-11T00:00:00+05:30</updated>
   <id>pi19404.github.io/2014/10/11/DFT1</id>
   <content type="html">&lt;h3&gt;Introduction&lt;/h3&gt;

&lt;p&gt;&lt;strong&gt;Fourier analysis&lt;/strong&gt; is generally concerned with the analysis and synthesis of functions. The decomposition of signal into easy-to-analyze components and the reconstruction from such components.&lt;/p&gt;

&lt;p&gt;In this article we will look at Fourier analysis of discrete time signals.&lt;/p&gt;

&lt;p&gt;Discrete time signal are defined at only particular set of time instances and are represented as sequence of real numbers that have continuous range of values&lt;/p&gt;

&lt;h3&gt;Fourier Series Representation of signal&lt;/h3&gt;

&lt;p&gt;A discrete time complex exponential is periodic in nature&lt;/p&gt;

&lt;p&gt;$ e^{j k\omega (n+N)} = e ^{j k \omega n} $
where  , $\omega=\frac{2\pi}{N}$&lt;/p&gt;

&lt;p&gt;The set of all discrete time time complex exponential signals that are periodic with period N is given by
$\phi_{k}[n] =  e ^{j k \frac{2\pi}{N} n} , \forall k \in \mathcal{Z}$&lt;/p&gt;

&lt;p&gt;$$ \phi_{k+rN}[n] = e ^{j (k+rN) \frac{2\pi}{N} n}  = e ^{j k \frac{2\pi}{N} n}  * e ^{j r N \frac{2\pi}{N} n}   $$
$$ \phi_{k+rN}[n] = e ^{j k \frac{2\pi}{N} n} e ^{j r  2\pi n} =e ^{j k \frac{2\pi}{N} n}$$&lt;/p&gt;

&lt;p&gt;When k is changed by integral multiples of N ,we get identical sequence.
Thus there are only N unique values of k for which we can define unique discrete time complex exponential sequence.&lt;/p&gt;

&lt;p&gt;$$ \begin{align} x[n]=\sum_{k} x[k] e^{j k \omega n} \end{align}$$&lt;/p&gt;

&lt;p&gt;$e^{j k \omega n} $ are only unique over N successive values of k,summation is only considered
over this range&lt;/p&gt;

&lt;p&gt;$$ \begin{align} x[n]=\sum_{k={N}} x[k] e^{j k \omega n} \end{align}$$&lt;/p&gt;

&lt;p&gt;$x[n]$ is  periodic with period N.&lt;/p&gt;

&lt;h3&gt;Discrete time Fourier Series&lt;/h3&gt;

&lt;p&gt;Let us consider a arbitrary periodic signal $x[n]$ with period N and that  $x[n]$ can be expressed in the form&lt;/p&gt;

&lt;p&gt;$$ \begin{align} x[n]=\sum_{k} X[k] \phi_{k}[n] \end{align}$$&lt;/p&gt;

&lt;p&gt;Thus we need to find out if $x[n]$ can be expressed in the above form and if so the coefficients $x[k]$ for which this representation is valid.&lt;/p&gt;

&lt;p&gt;The theoretical derivations for the same can be found in all signal processing references.The result are as follows&lt;/p&gt;

&lt;p&gt;$$ \begin{align} X[k] =\sum_{n=0}^{N-1}x[n] e^{- j k \frac{2\pi}{ N} n } \end{align}$$ and 
$$\begin{align} x[n] =\frac{1}{N}\sum_{k=0}^{N-1}X[k]\,e^{j k \frac{2\pi}{ N} n } \end{align} $$&lt;/p&gt;

&lt;p&gt;$X[k]$ are called as &lt;strong&gt;Fourier series coefficients&lt;/strong&gt;.The coefficients are also referred to as spectral coefficients of signal $x[n]$.&lt;/p&gt;

&lt;p&gt;The representation of signal $x[n]$ in terms of spectral  coefficients is called as the &lt;strong&gt;Fourier series representation&lt;/strong&gt; of the signal&lt;/p&gt;

&lt;p&gt;These coefficient specify the decomposition of signal $x[n]$ into sum of N harmonically related complex exponential .&lt;/p&gt;

&lt;p&gt;Any periodic discrete time signal $x[n]$ can be represented using the Fourier series representation 
and Fourier series representation enable us to represent any periodic signal as weighted sum of complex exponential s.&lt;/p&gt;

&lt;p&gt;Let us look at some examples to understand what information can Fourier series representation of a signal give us.&lt;/p&gt;

&lt;pre class=&quot;brush: python&quot;&gt;
def FourierSeries(input,N=None):
    &quot;&quot;&quot; computes the fourier series coefficients of input signal
    
    Parameters
    -----------
    input : numpy array
            input discrete time signal
            
    Returns
    --------
    out : complex,list
          fourier series coefficients
    &quot;&quot;&quot;
    
    N=len(input);

    w=2*cmath.pi/N;
    input=input[0:N];
    n=numpy.arange(0,N);    
    r=cexp(-1j*w*n);

    output = [complex(0)] * N    
    for k in range(N):        
        r=input*cexp(-1j*w*n*k)          
        output[k]=np.sum(r);
        
   
    return output;

&lt;/pre&gt;

&lt;p&gt;Let us consider a sinusoidal signal with frequency $f_{s}=10Hz$,for a duration of 1sec
Lets sample this waveform at $F_{s}=150Hz$ and observe the Fourier series coefficients of the signal&lt;/p&gt;

&lt;p&gt;we sample at 150Hz,In the frequency spectrum,just consider a single period of the cosine waveform,ie 
$F_{s}/f_{s}=15$ samples.The output can be seen in subplot 2&lt;/p&gt;

&lt;p&gt;we take complete signal,and compute the Fourier series coefficients,output can be seen in subplot 3&lt;/p&gt;

&lt;p&gt;Let us consider  magnitude plot of Fourier series&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://googledrive.com/host/0B-pfqaQBbAAtbExWN0Zya3JySzA/image2.png&quot; alt=&quot;enter image description here&quot;&gt;&lt;/p&gt;

&lt;pre class=&quot;brush : python &quot;&gt;
def FourierSinusoids(F,w,Fs,synthesis=None):    
    &quot;&quot;&quot; the function generates a discrete time sinusoid,computes
    the Fourier series coefficients and plots the time and frequency
    data 
 
     Paraneters
     ----------
     F : numpy array
         sinuoidal frequency components
         
     w  : numpy array
          the weights associated with freuency components
         
     Fs : Integer
          sampling frequency
          
     synthesis : int
                 if 1 ,reconstructs signal and plots the original and reconstructed
                 signal
 
    &quot;&quot;&quot;
    if synthesis==None:
        synthesis=0;
        
    Ts=1.0/Fs;   
    xs=numpy.arange(0,1,Ts) 
    
    signal=numpy.zeros(np.shape(xs));
    for i in range(len(F)):
        omega=2*np.pi*F[i];
        signal = signal+ w[i]*numpy.cos(omega*xs);
    #plot the time domain signal    
    subplot(2,1,1)
    plt.plot(range(0,len(signal)),signal)
    xlabel('Time')
    ylabel('Amplitude')
    title('time doman')
    #plt.ylim(-2, 2)
    
    #compute fourier series coefficients
    r1=FourierSeries(signal)
    a1=cabs(r1)
    
    if synthesis==0:
        #plot the freuency domain signal
        L=len(a1);
        fr=np.arange(0,L);
        subplot(2,1,2)
        plt.stem(fr,a1,'r') # plotting the spectrum
        xlabel('Freq (Hz)')
        ylabel('|Y(freq)|')
        title('complete signal')
        ticks=np.arange(0,L+1,25);
        plt.xticks(ticks,ticks);     
        show() 
        
    if synthesis==1:
        rsignal=IFourierSeries(r1);
        print np.allclose(rsignal, signal)    
        subplot(2,1,2) 
        plt.stem(xs,signal)
        xlabel('Time')
        ylabel('Amplitude')
        title('reconstructed signal')
        show() 


if __name__ == &quot;__main__&quot;:     

    mode =0
    
    if mode==0:
        F=[10];
        F=np.array(F);
        w=numpy.ones(F.shape);
        #plot the time domain signal and fourier series component
        FourierSinusoids(F,w,150);
&lt;/pre&gt;

&lt;p&gt;we can see that the frequency corresponding to 10Hz we can observe peak.The total number of Fourier
series coefficients are equal to the total number of input samples.&lt;/p&gt;

&lt;p&gt;Now let us consider a combination of sinusoidal signals at freuency 10 and 15Hz.The signal is periodic with frequency which is LCM of 10 and 15 ie 5Hz.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://googledrive.com/host/0B-pfqaQBbAAtbExWN0Zya3JySzA/image4.png&quot; alt=&quot;enter image description here&quot;&gt;&lt;/p&gt;

&lt;pre class=&quot;brush : python &quot;&gt;
    if mode==1:
        F=[10,20];
        F=np.array(F);
        w=numpy.ones(F.shape);
        FourierSinusoids(F,w,150); 
&lt;/pre&gt;

&lt;p&gt;Now lets keep on adding frequency components.The below signal is periodic with period of 1 sec &lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://googledrive.com/host/0B-pfqaQBbAAtbExWN0Zya3JySzA/image5.png&quot; alt=&quot;enter image description here&quot;&gt;&lt;/p&gt;

&lt;pre class=&quot;brush : python &quot;&gt;

    if mode==2:
        F=range(1,10);
        F=np.array(F);
        w=numpy.ones(F.shape);      
        FourierSinusoids(F,w,150);    
&lt;/pre&gt;

&lt;h3&gt;Synthesis of Signal&lt;/h3&gt;

&lt;p&gt;In the earlier section we saw the process of decomposition of aperiodic signal into its frequency components.&lt;/p&gt;

&lt;p&gt;we will now look at the &lt;strong&gt;synthesis of signal&lt;/strong&gt; from its Fourier series coefficients.&lt;/p&gt;

&lt;p&gt;$${x[n] =
\frac{1}{N}\sum_{k=0}^{N-1}X[k]\,e^{j k \frac{2\pi}{ N} n }}$$&lt;/p&gt;

&lt;p&gt;Below is plot of the original and reconstructed signal and python code for the &lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://googledrive.com/host/0B-pfqaQBbAAtbExWN0Zya3JySzA/image6.png&quot; alt=&quot;enter image description here&quot;&gt;&lt;/p&gt;

&lt;pre class=&quot;brush : python &quot;&gt;
def IFourierSeries(input):
    &quot;&quot;&quot; function reconstructs the signal from fourier series coefficients
    
    Parameters
    ---------
    input : cmath list
            fourier series coefficients    
    
    Returns
    -----------
    out : numpy arrary
          reconstructed signal
    
    &quot;&quot;&quot;
    N=len(input);
    w=2*cmath.pi/N;
    k=numpy.arange(0,N);    
    output = [complex(0)] * N   
    for n in range(N):  
        r=input*cexp(-1j*w*n*k);
        output[n]=np.mean(r);

    print output.__class__    
    return output;


    if mode==3:
        F=range(1,10);
        F=np.array(F);
        w=numpy.ones(F.shape);
        FourierSinusoids(F,w,150,1); 
&lt;/pre&gt;

&lt;h3&gt;Discrete  Fourier Transform&lt;/h3&gt;

&lt;p&gt;Now arises the situation what do we do for a-periodic signals.After a lot of theorotical analysis
on Discrete time Fourier transform and sampling in the frequency domain,it turns out
we just assume periodic extension of aperiodic signal and compute Fourier series as above.&lt;/p&gt;

&lt;p&gt;The Fourier series coefficients for a periodic signal are also periodic with same period N&lt;/p&gt;

&lt;p&gt;$$X[k+N]=X[k]$$&lt;/p&gt;

&lt;p&gt;If we consider a single period of N values of Fourier series coefficient ,we obtain a finite duration sequence
which is called Discrete Fourier Transform (DFT).&lt;/p&gt;

&lt;p&gt;Thus by computing the DFT we obtain the Fourier series coefficients for single period.&lt;/p&gt;

&lt;p&gt;It is upto us to choose a period of the signal.Let us consider a aperiodic impulse of length 150 and on-duty cycle of 5.&lt;/p&gt;

&lt;p&gt;Let us consider N=150,450 and observe the results.
&lt;img src=&quot;https://googledrive.com/host/0B-pfqaQBbAAtbExWN0Zya3JySzA/image7.png&quot; alt=&quot;enter image description here&quot;&gt;&lt;/p&gt;

&lt;p&gt;At we increase the period of the signal we can see that resolution in the freuency domain increases.&lt;/p&gt;

&lt;p&gt;As $N \rightarrow \infty$ ,the samples in the freuency domain will be placed closer and closer .
If samples in frequency domain are spaced infinitely closely,it can be considered a continuous signal.
This gives us Discrete Time Fourier Transform representation of the signal.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://googledrive.com/host/0B-pfqaQBbAAtbExWN0Zya3JySzA/image8.png&quot; alt=&quot;enter image description here&quot;&gt;&lt;/p&gt;

&lt;pre class=&quot;brush : python &quot;&gt;
def FourierRect(N):     
        &quot;&quot;&quot; the function generates rectangular aperiodic pulse and computer the DFT coefficients
        
        Parameters
        ----------
        N : period of aperiodic signal
             
        &quot;&quot;&quot;
        x = np.zeros((1,N))
        x[:,0:30]=1;
        x=x.flatten();
    
        
        #compute the DFT coefficients
        r1=FourierSeries(x)
        #magnitude of DFT coefficients
        a1=cabs(r1)

        #plot the time domain signal
        subplot(2,1,1)
        plt.plot(range(0,len(x)),x)
        xlabel('Time')
        ylabel('Amplitude')
        title('time doman')
        plt.ylim(-2,2);
        
        #plot the DFT coefficients
        L=len(a1);
        fr=np.arange(0,L);
        subplot(2,1,2)
        plt.stem(fr,a1,'r') # plotting the spectrum
        xlabel('Freq (Hz)')
        ylabel('|Y(freq)|')
        title('complete signal')
        ticks=np.arange(0,L+1,25);
        plt.xticks(ticks,ticks);     
        show() 

    if mode==4:
       FourierRect(150);

    if mode==5:
       FourierRect(150*3);        
&lt;/pre&gt;

&lt;p&gt;It samples in frequency domain are spaced infinitely closely,it can be considered a continuous signal.
This representation of is called as Fourier Transform.&lt;/p&gt;

&lt;p&gt;$$ X(k) = \sum x[n] exp(-j\omega k n)  $$&lt;/p&gt;

&lt;p&gt;distance between adjacent samples is $\omega$ .As $ w \rightarrow 0 $ samples are placed infinitely closely with each other .&lt;/p&gt;

&lt;p&gt;$$ X(w) = \sum x[n] exp(-j\omega  n)  $$&lt;/p&gt;

&lt;p&gt;Fourier transform is continuous in nature and cannot be used for numeral computation .&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Discrete Fourier transform&lt;/strong&gt; is sampled version of Discrete Time Fourier transform of a  signal and in in a form that is suitable for numerical computation on a signal processing unit.&lt;/p&gt;

&lt;p&gt;A fast Fourier transform (FFT) is an algorithm to compute the discrete Fourier transform (DFT) and its inverse.It is a efficient way to compute the DFT of a signal.&lt;/p&gt;

&lt;p&gt;we will use the  python FFT routine can compare the performance with naive implementation&lt;/p&gt;

&lt;p&gt;Using the inbuilt FFT routine :Elapsed time was 6.8903e-05 seconds&lt;/p&gt;

&lt;p&gt;Using the naive code :Elapsed time was 0.0653119 seconds&lt;/p&gt;

&lt;p&gt;we can see improvement of order of 1000&lt;/p&gt;

&lt;p&gt;The naive algorithm has complexity of $o(N^2)$ and FFT algorithm as complexity of $O(N log N)$&lt;/p&gt;

&lt;pre class=&quot;brush : python &quot;&gt;
    if mode==6:
        Fs=150;
        F=range(1,10);
        F=np.array(F);        
        w=numpy.ones(F.shape);

        
        Ts=1.0/Fs;   
        xs=numpy.arange(0,1,Ts) 
    
        signal=numpy.zeros(np.shape(xs));
        for i in range(len(F)):
            omega=2*np.pi*F[i];
            signal = signal+ w[i]*numpy.cos(omega*xs);        
            
            
        start_time = time.time()
        FourierSeries(signal)
        end_time = time.time()
        print(&quot;Elapsed time naive algo  %g seconds&quot; % (end_time - start_time)) 

        start_time = time.time()
        fft(signal)
        end_time = time.time()
        print(&quot;Elapsed time of fft algo  %g seconds&quot; % (end_time - start_time)) 
&lt;/pre&gt;      

&lt;h4&gt;Circular Convolution and DFT&lt;/h4&gt;

&lt;h5&gt;Circular Shift of a sequence&lt;/h5&gt;

&lt;p&gt;Let $x[n]$ denote the finite length time domain sequence&lt;/p&gt;

&lt;p&gt;Once we take DFT ,in time domain we are constructing the periodic extension of the signal
Thus a time shit of signal is actually implies circular shit of the signal.&lt;/p&gt;

&lt;p&gt;$$x[n] \Leftrightarrow X[k] $$
$$x[(n-n_{o})_{N}]  \Leftrightarrow e^{-j k \omega n_{o}} X[k]$$ &lt;/p&gt;

&lt;p&gt;One of the most basic application in signal processing is linear convolution.&lt;/p&gt;

&lt;p&gt;It can be used to represents the output of discrete time LTI system,correlation and cross correlation,
filtering and host of other signal processing operations.&lt;/p&gt;

&lt;p&gt;Linear Convolution in discrete time system is represented as&lt;/p&gt;

&lt;p&gt;$$y[n]=\sum_{i} x[i] h[n-i]$$&lt;/p&gt;

&lt;p&gt;The signals $x[n]$ and $h[n]$ are finite duration discrete time signals .&lt;/p&gt;

&lt;p&gt;Linear convolution of 2 sequences of length M,L  results in sequence of length M+L-1&lt;/p&gt;

&lt;p&gt;An associated discrete time Fourier transform property &lt;/p&gt;

&lt;p&gt;$$Y\left(\Omega\right) = X\left(\Omega\right)H\left(\Omega\right)$$&lt;/p&gt;

&lt;p&gt;Let us consider 2 sequences,take their DFT,multiply them and then take the inverse
&lt;strong&gt;&lt;code&gt;Circular convolution in time domain leads to multiplication of DFT coefficients in the frequency domain&lt;/code&gt;&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;lets take the seuences &lt;code&gt;[1,1,1,1,1]&lt;/code&gt; and &lt;code&gt;[1,2,3,4]&lt;/code&gt;&lt;/p&gt;

&lt;pre class=&quot;brush : python &quot;&gt;
The result of linear convolution is `[ 1  3  6 10 10  9  7  4 ]`
The result of inverse of product of DFT coefficients is `[ 10.  10.  10.  10.  10.]`
&lt;/pre&gt;

&lt;p&gt;we take N point DFT of signals,N=max(M,L)&lt;/p&gt;

&lt;pre class=&quot;brush : python &quot;&gt;
...|1 1 1 1 1|1 1 1 1 1|1 1 1 1 1|....
...|1 2 3 4 0|1 2 3 4 0|1 2 3 4 0|....
Result 
...|10|10|10| ...
&lt;/pre&gt;

&lt;p&gt;Taking the DFT leads to periodicity in time domain,now we perform convolution as usual.
the $h[n-n_{o}]$ will be circularly shifted&lt;/p&gt;

&lt;pre class=&quot;brush : python &quot;&gt;
...|1 1 1 1 1|1 1 1 1 1|1 1 1 1 1|....
...|0 1 2 3 4|0 1 2 3 4|0 1 2 3 4|....

Result 
...|10|10|10| ...
&lt;/pre&gt;

&lt;pre class=&quot;brush : python &quot;&gt;
...|1 1 1 1 1|1 1 1 1 1|1 1 1 1 1|....
...|4 0 1 2 3 |4 0 1 2 3|4 0 1 2 3|....

Result 
...|10|10|10| ...
&lt;/pre&gt;

&lt;p&gt;After N shifts we are repeating the sequence
Thus we perform the convolution of N shifts equivalent to the period of sequence in time domain&lt;/p&gt;

&lt;pre class=&quot;brush : python &quot;&gt;
Circular convolution
[ 10.  10.  10.  10.  10.]
&lt;/pre&gt;

&lt;p&gt;Circular shift  is consequence of periodicity introduced by the DFT  and results in circular convolution operation&lt;/p&gt;

&lt;p&gt;We can consider this due to the time aliasing being introduced due to sampling in the frequency domain.
The sampling theorem states that to avoid aliasing in frequency domain the sampling rate must be greater than twice the maximum frequency of signal being sampled.&lt;/p&gt;

&lt;p&gt;We had mentioned earlier that DFT is the sampled version of DTFT .The question arises that how do we increase the sampling rate to avoid time domain aliasing.&lt;/p&gt;

&lt;p&gt;We saw that zero padding the sequence leads to samples of Fourier series are placed more closely together.Equivalent to saying increases the sampling rate of DTFT in frequency domain,&lt;/p&gt;

&lt;p&gt;This gives us a intuition that if we zero pad the sequence,it will lead to increased sampling rate of the DTFT of the signal.&lt;/p&gt;

&lt;p&gt;For the result of circular convolution to be equal to the linear convolution,we simply zero pad the sequences to length of M+L-1.&lt;/p&gt;

&lt;pre class=&quot;brush : python &quot;&gt;
...|1 1 1 1 1 0 0 0 0 |1 1 1 1 1 0 0 0 0 |
...|1 2 3 4 0 0 0 0 0 |1 2 3 4 0 0 0 0 0 |

result : 10

...|1 1 1 1 1 1 0 0 0 |1 1 1 1 1 0 0 0 0 |
...|0 1 2 3 4 0 0 0 0 |0 1 2 3 4 0 0 0 0 |

result : 10

...|1 1 1 1 1 1 0 0 0 |1 1 1 1 1 0 0 0 0 |
...|0 0 1 2 3 4 0 0 0 |0 0 1 2  3 4 0 0 0 |

result : 9
&lt;/pre&gt;

&lt;p&gt;thus we can see that due to zero padding,the circular shifted components are zeros
and the result obtained is equivalent to linear convolution result.&lt;/p&gt;

&lt;p&gt;The code for the above example is given below&lt;/p&gt;

&lt;pre class=&quot;brush : python &quot;&gt;
    if mode == 7:
        x=np.array([1,1,1,1,1]);
        h=np.array([1,2,3,4,0]);
        r=np.convolve(x,h)
        print 'Linear convolution'
        print r

        #take 5 point DFT of the sequence
        f1=fft(x,5);
        f2=fft(h,5);
        s=ifft(f1*f2);
        print 'Circular convolution'
        print abs(s)
        
        #take 9 point DFT of sequence
        f1=fft(x,9);
        f2=fft(h,9);
        s=ifft(f1*f2);
        print 'zero padded Circular convolution'
        print r
&lt;/pre&gt;
        

&lt;h3&gt;Code&lt;/h3&gt;

&lt;p&gt;The code for all the examples can be found at github repository
&lt;a href=&quot;https://github.com/pi19404/pyVision/tree/master/pySignalProc/tutorial/fourierSeries.py&quot;&gt;https://github.com/pi19404/pyVision/tree/master/pySignalProc/tutorial/fourierSeries.py&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;You can change the mode variable in the file from 1-7 to generate all the plots shown in the article&lt;/p&gt;

&lt;p&gt;The file fourierSeries.py can also be downloaded from below link&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&quot;http://www.codeproject.com/KB/Articles/828166/pySignalProc.zip&quot;&gt;Download Link&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
</content>
 </entry>
 
 <entry>
   <title>Multilayer Perceptron in Python</title>
   <link href="pi19404.github.io/2014/10/03/test/"/>
   <updated>2014-10-03T00:00:00+05:30</updated>
   <id>pi19404.github.io/2014/10/03/test</id>
   <content type="html">&lt;h2&gt;Introduction&lt;/h2&gt;

&lt;p&gt;In this article we will look at supervised learning algorithm called Multi-Layer Perceptron (MLP) and implementation of single hidden layer MLP&lt;/p&gt;

&lt;h3&gt;Perceptron&lt;/h3&gt;

&lt;p&gt;A perceptron is a  unit that computes a single output from multiple real-valued inputs by forming a linear combination according to its input weights and then possibly putting the output through some nonlinear function called the activation function&lt;/p&gt;

&lt;p&gt;Below is a figure illustrating the operation of perceptron&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://googledrive.com/host/0B-pfqaQBbAAtbExWN0Zya3JySzA/images1.jpg&quot; alt=&quot;enter image description here&quot;&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://encrypted-tbn3.gstatic.com/images?q=tbn:ANd9GcSPBshuqpGJBgvzx9ECppUv6QBg7ipgPH4XDEle3gZVn3Ku56MT&quot;&gt;figure taken from&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;The output of perceptron can be expressed as &lt;/p&gt;

&lt;p&gt;$f(x) = G( W^T x+b)$&lt;/p&gt;

&lt;p&gt;$x$ is the input vector 
$(W,b)$ are the parameters of perceptron 
 $f$ is the non linear function&lt;/p&gt;

&lt;h3&gt;Multi Layer Perceptron&lt;/h3&gt;

&lt;p&gt;The MLP network consists of input,output and hidden layers.Each hidden layer consists of numerous perceptron&amp;#39;s which are called hidden units&lt;/p&gt;

&lt;p&gt;Below is figure illustrating a feed forward neural network architecture for Multi Layer perceptron&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://googledrive.com/host/0B-pfqaQBbAAtbExWN0Zya3JySzA/mlp1.png&quot; alt=&quot;enter image description here&quot;&gt;&lt;a href=&quot;http://www.deeplearning.net/tutorial/_images/mlp.png&quot;&gt;(figure taken from)&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;A single-hidden layer MLP  contains a array of perceptrons .
The output of hidden layer of MLP can be expressed as a function &lt;/p&gt;

&lt;p&gt;$f(x) = G( W^T x+b)$&lt;/p&gt;

&lt;p&gt;$f: R^D \rightarrow R^L$, 
where D is the size of input vector $x$ 
$L$ is the size of the output vector
$G$ is activation function.&lt;/p&gt;

&lt;p&gt;In case the activation function G is a sigmoid function then a single-layer MLP consisting of just the output layer is equivalent to a logistic classifier         &lt;/p&gt;

&lt;p&gt;$\begin{align} f_{i}(x)=\frac{e^{W_{i}x+b_{i}}}{\sum_{j} e^{W_{j}x+b_{j}}} \end{align}$&lt;/p&gt;

&lt;p&gt;Each unit of input layer corresponds to element of input vector.
Each output unit of logistic classifier generate a prediction probability that input vector belong to a specified class.&lt;/p&gt;

&lt;h2&gt;Feed Forward Neural Network&lt;/h2&gt;

&lt;p&gt;Let us first consider the most classical case of a single hidden layer neural network&lt;/p&gt;

&lt;p&gt;The number of inputs to hidden layer is $(d)$ and number of outputs of hidden layer are $(m)$
The hidden layer performs mapping  of vector of dimensionality $d$ to vector of dimensionality $m$.&lt;/p&gt;

&lt;p&gt;Each unit of hidden layer of a MLP can be parameterized by a  weight matirx and bias vector  $(W,b)$ and a activation function $(\mathcal{G})$.The output of a hidden layer is activation function applied to linear combination of input and weight vector.&lt;/p&gt;

&lt;p&gt;Dimensionality of weight matrix and bias vector are determined by desired number of output units.
If the number of  inputs to hidden layer/dimensionality of input is $\mathcal{M}$ and number of outputs is $\mathcal{N}$ then dimensionality of weight vector in $\mathcal{NxM}$ and that of  bias vector is $\mathcal{N}x1$.&lt;/p&gt;

&lt;p&gt;We can consider that hidden layer consists of $\mathcal{N}$ hidden units ,each of which accepts a $\mathcal{M}$ dimensional vector and produces a single output.&lt;/p&gt;

&lt;p&gt;The output is the affine transformation of the input layer followed by the appplication of function $f(x)$ ,which is typically a non linear function like sigmoid of inverse tan hyperbolic function.&lt;/p&gt;

&lt;p&gt;The vector valued function  $h(x)$  is the output of the hidden layer.&lt;/p&gt;

&lt;p&gt;$$ h(x) = f(W^T x + c ) $$&lt;/p&gt;

&lt;p&gt;The output layer of MLP is typically Logistic regresson classifier,if probabilistic outputs are desired for classification purposes in which case the activation function is the softmax regression function.&lt;/p&gt;

&lt;h3&gt;Single Hidden Layer Multi Layer Perceptron&amp;#39;s&lt;/h3&gt;

&lt;p&gt;Let ,&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;$h_{i-1}$ denote the input vector to the i-th  layer&lt;/li&gt;
&lt;li&gt;$h_{i}$ denote the output vector of the i-th layer.&lt;/li&gt;
&lt;li&gt;$h_{0}$=x is vector that represents input layer &lt;/li&gt;
&lt;li&gt;$h_{n}=y$ is output layer which produces the desired prediction output.&lt;/li&gt;
&lt;li&gt;$f(x)$ denote the activation function &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Thus we denote the output of each hidden layer as&lt;/p&gt;

&lt;p&gt;$h_{k}(x) = f(b_{k} + w_{k}^T h_{i-1}(x)) = f(a_{k}) $&lt;/p&gt;

&lt;p&gt;Considering sigmoid activation function,gradient of fundtion wrt arguments can be written as&lt;/p&gt;

&lt;p&gt;$\begin{align} \frac{\partial \mathbf{h}_{k}(x)  }{\partial \mathbf{a}_{k}}=  f(a_{k})(1- f(a_{k})) \end{align}$ &lt;/p&gt;

&lt;p&gt;The computation associated with each hidden unit $(i)$ of the layer can be denoted as&lt;/p&gt;

&lt;p&gt;$$h_{k,i}(x) = f(b_{k,i} + W_{k,i}^T h_{i-1}(x)) = f(a_{k}(x))$$&lt;/p&gt;

&lt;p&gt;The output layer is a Logistic regression classifier.The output is a probabilistic output denoting the confident that input belongs to the predicted class.The cost function defined for the same is defined as negative log likelyhood over the training data&lt;/p&gt;

&lt;p&gt;$$L = -log (p_{y}) $$&lt;/p&gt;

&lt;p&gt;The idea is to maximize $p_{y}= P( Y =y_{i} | x )$ as estimator of conditional probability of the class $y$ given that input is $x$.This is the cost function for training algorithm.&lt;/p&gt;

&lt;h3&gt;Back-Propagation Algorithm&lt;/h3&gt;

&lt;p&gt;The Back-Propagation Algorithm is recursive gradient algorithm used to optimize the parameters MLP wrt to defined loss function.Thus our aim is that each layer of MLP the hidden units are computed so that cost function is maximized.&lt;/p&gt;

&lt;p&gt;Like in logistic regression we compute the gradients of weights wrt to the cost function . The gradient of the cost function wrt all the weights in various hidden layers are computed.Standard gradient based optimization is performed to obtain the parameters that will minimize the likelihood function.&lt;/p&gt;

&lt;p&gt;The output layer determines the cost function.Since we are using Logistic regression as output layer.The cost function is the softmax function.Let L denote the cost function.&lt;/p&gt;

&lt;p&gt;There is nothing different we do in backpropagation algorithm that any other optimization techniue.The aim is to determine how the weights and biases change in the network &lt;/p&gt;

&lt;p&gt;$ \begin{align} \frac{\partial L}{\partial W_{k,i,j} } \text{ and } \frac{\partial L}{\partial b_{k,i,j} } \end{align}$.&lt;/p&gt;

&lt;h4&gt;output layer&lt;/h4&gt;

&lt;p&gt;$\begin{align} L = -log ( f(a_{k,i}) ) \end{align}$&lt;/p&gt;

&lt;p&gt;$\begin{align} \frac{\partial L  }{\partial \mathbf{a}_{k,i}} = \frac{\partial L  }{\partial \mathbf{h}_{k,i}} \frac{\partial \mathbf{h}_{k,i} }{\partial \mathbf{a}_{k,i}} = -\frac{1}{h_{k,i}} * h_{k,i}*(1-h_{k,i}) = (h_{k,i}-1)\end{align}  $&lt;/p&gt;

&lt;p&gt;$ \begin{align} \frac{\partial L  }{\partial \mathbf{a}_{k,i}} =\mathbf{h}_{k,j} - 1_{y=y_{i}} \end{align}$&lt;/p&gt;

&lt;p&gt;The above expression can be considered as the error in output.When $y=y_{i}$ the error is $(1-p_{i})$ and then $y \ne y_{i}$ the error in prediction is $p_{i}$.&lt;/p&gt;

&lt;h4&gt;hidden layer&lt;/h4&gt;

&lt;p&gt;$\begin{align}\frac{\partial L }{\partial \mathbf{a}_{k-1,j}} =  \frac{\partial L }{\partial \mathbf{h}_{k-1,j}} \frac{\partial \mathbf{h}_{k-1,j} }{\partial \mathbf{a}_{k-1,j}} \end{align}$&lt;/p&gt;

&lt;p&gt;Thus the idea is to start computing gradients from the bottom most layer.To compute the gradients of the cost function wrt parameters at the i-th layer we need to know the gradients of cost function wrt parameters at $(i+1)$th layer.&lt;/p&gt;

&lt;p&gt;We start with gradient computation at the logistic classifier level.The propagate backwards,updating the parameters at each layer&lt;/p&gt;

&lt;p&gt;Let us consider the case of other other hidden layers&lt;/p&gt;

&lt;p&gt;$\begin{align} \frac{\partial L }{\partial \mathbf{h}_{k-1,j}} = \sum_{i} \frac{\partial L }{\partial \mathbf{a}_{k,i}}\frac{\partial \mathbf{a}_{k,i} }{\partial \mathbf{h}_{k-1,j}} = \sum_{i} \frac{\partial L }{\partial \mathbf{a}_{k,i}} W_{k,i,j}  \end{align} $&lt;/p&gt;

&lt;p&gt;The implementation of the above equation &lt;/p&gt;

&lt;pre class=&quot;brush : python &quot;&gt;
    def linear_gradient(self,weights,error):   
            &quot;&quot;&quot; The function compues gradient of likelihood function wrt output of hidden layer
            :math:`\\begin{align} \\frac{\partial L }{\partial \mathbf{h}\_{k-1,j}} \\end{align}`
            
            Parameters 
            ------------
            weights : ndarray,shape=(n_out,n_hidden)
                      weights of next hidden layer, :math:`\\begin{align} \mathbf{W}\_{k,i,j}  \\end{align}`
                      
            error   : ndarray,shape=(n_out,)
                      backpropagated error from next layer :math:`\\begin{align} \\frac{\partial L }{\partial \mathbf{a}\_{k,i}} \\end{align}`
        
            Returns 
            -----------     
            out : ndarray,shape=(n_hidden,)                
                  compute the backpropagated error, :math:`\\begin{align} \\frac{\partial L }{\partial \mathbf{h}\_{k-1,j}} \\end{align}`
            &quot;&quot;&quot;            
            
            return numpy.dot(error,weights);
&lt;/pre&gt;

&lt;p&gt;The gradients computation of parameters of hidden layers is as follows&lt;/p&gt;

&lt;p&gt;$\begin{align}\frac{\partial L }{\partial \mathbf{W}_{k-1,i,j}} =  \frac{\partial L }{\partial \mathbf{a}_{k-1,j}} \frac{\partial \mathbf{a}_{k-1,j} }{\partial \mathbf{W}_{k-1,i,j}}=\frac{\partial L }{\partial \mathbf{a}_{k-1,j}} \mathbf{h}_{k-2,j} \end{align}$&lt;/p&gt;

&lt;p&gt;$\begin{align}\frac{\partial L }{\partial \mathbf{b}_{k-1,i}} =  \frac{\partial L }{\partial \mathbf{a}_{k-1,i}} \frac{\partial \mathbf{a}_{k-1,i} }{\partial \mathbf{b}_{k-1,i}}=\frac{\partial L }{\partial \mathbf{a}_{k-1,i}}  \end{align}$&lt;/p&gt;

&lt;p&gt;This is implemented as below ,where the input&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;$x$ represents $\begin{align} \frac{\partial \mathbf{h}_{k,j} }{\partial \mathbf{a}_{k,j}} \end{align}$ -output gradient&lt;/li&gt;
&lt;li&gt;$y$ represents $\begin{align} h_{k-2,j} \end{align}$ -activation&lt;/li&gt;
&lt;li&gt;$w$ represents $\begin{align} \frac{\partial L }{\partial \mathbf{a}_{k-1,i}}\end{align}$ -error&lt;/li&gt;
&lt;/ul&gt;

&lt;pre class=&quot;brush : python &quot;&gt;
   
    def compute_error(self,x,w,y):      
        &quot;&quot;&quot;                 
        function computes the gradient of the likelyhood function wrt to parameters  of the hidden layer for single input
        

        Parameters 
        -------------
        x : ndarray,shape=(n_hidden,)

        w : ndarray,shape=(n_hidden,)
            `w` represents :math:`\\begin{align} \\frac{\partial L }{\partial \mathbf{h}\_{k,i}}\end{align}` the gradient of the likelyhood fuction wrt output of hidden layer
            
        y : ndarray,shape=(n_in,)
            `y` represents :math:`\mathbf{h}\_{k-2,j}` the input hidden layer
        
        Returns
        ------------
        res : ndarray,shape=(n_in+1,n_hidden)        
              :math:`\\begin{align} \\frac{\partial L }{\partial \mathbf{W}\_{k-1,i,j}}  \\text{ and } \\frac{\partial L }{\partial \mathbf{W}\_{k-1,i}} \end{align}`
        &quot;&quot;&quot;        
       
        
        x=x*w;                
        #gradient of likelyhood function wrt input activation
        res1=x.reshape(x.shape[0],1);
        #gradient of likelyhood function wrt weight matrix
        res=np.dot(res1,y.reshape(y.shape[0],1).T);
        self.eta=0.0001
        #code for L1 and L2 regularization 
        if self.Regularization==2:
           res=res+self.eta*self.W;
        if self.Regularization==1:
           res=res+self.eta*np.sign(self.W);

        #stacking the parameters and preparing for returning            
        res=np.hstack((res,res1));
        return res.T;


    def cost_gradients(self,weights,activation,error):        
        &quot;&quot;&quot; function to compute the gradient of log 
        likelyhood function wrt the parameters of the hidden layer
        averaged over all the input samples.        
        
        Parameters 
        -------------
        weights : numpy,shape(n_out,n_hidden),
                  weight matrix of the next layer,W\_{k,i,j} 
                  
                  
        activation: numpy,shape=(N,n_in)
                    input to the hidden layer \mathbf{h}\_{k-2,j}
                    
        error : numpy,shape=(n_out,) 
                 \frac{\partial L }{\partial \mathbf{a}\_{k,i}}
        
        Returns
        
        -------------
        gW : ndarray,shape=(n_hidden,n_in+1)
             coefficient parameter matrix of next hidden layer,
             :math:`\\begin{align} \\frac{\partial L }{\partial \mathbf{W}\_{k-1,i,j}}  \\text{ and } \\frac{\partial L }{\partial \mathbf{W}\_{k-1,i}} \end{align}`
        &quot;&quot;&quot;                                       
        we=self.linear_gradient(weights,error)
        ag=self.activation_gradient()
        e=[ self.compute_error(a,we,b) for a,b in izip(ag,activation)]
        gW=np.mean(e,axis=0).T        
        return gW;        
&lt;/pre&gt;

&lt;p&gt;Once we have the gradients and have computed the new parameters,the &lt;code&gt;function update&lt;/code&gt; is called to updated the new parameters in the model.&lt;/p&gt;

&lt;p&gt;This function is called by the Optimizer module that performs SGD based optimizations,all the optimization parameters like learning rate are handled by the optimizer methods.&lt;/p&gt;

&lt;pre class=&quot;brush : python &quot;&gt;
    def update_parameters(self,params):
        &quot;&quot;&quot; function to updated the learn parameters to the model
        
        Parameters
        ----------
        grads : ndarray,shape=(n_hidden,n_in+1)        
                coefficient parameter matrix                
        
        &quot;&quot;&quot;
        
        self.params=params;
        param1=self.params.reshape(-1,self.nparam);
        self.W=param1[:,0:self.nparam-1];
        self.b=param1[:,self.nparam-1];
        
&lt;/pre&gt;

&lt;h3&gt;Implementation Details&lt;/h3&gt;

&lt;p&gt;The class HiddenLayer encapsulates all the methods for prediction,classification,training,gradient computation and error propagation that are required&lt;/p&gt;

&lt;p&gt;The important attributes of the HiddenLayer class are &lt;/p&gt;

&lt;pre class=&quot;brush : python &quot;&gt;
    Attributes        
    -----------
    `out` : array-like ,shape=[n_out]
    The output of hidden layer 
    
    `params`:array-like ,shape=[n_out,n_in+1]        
     parameters of hidden layer
    
    `W,b`:array-like,shape=[n_out,n_int],shape=[n_out,1]
     parameters in the form of weight matrix and bias vector characterizing 
     the hidden layer
     
     `activation`:function
     the non linear activation function
     
    .. note :
    in the below functions to n_hidden denotes the number of output units of present hidden layer
    n_out denotes the number of output units of next hidden layer
    and n_in denotes the size of input vector to present hidden layer
    
    def compute(self,input):
        &quot;&quot;&quot;function computes the output of the hidden layer for input matrix
      
        Parameters
        ----------
        input   :   ndarray,shape=(N,n_in)
                    :math:`h\_{i-1}(x)` is the `input`

        Returns
        -----------
        output  : ndarray ,shape=(N,n_out)
                    :math:`f(b_k + w_k^T h\_{i-1}(x))` ,affine transformation over input
        &quot;&quot;&quot;                
        #performs affine transformation over input vector        
        linout=numpy.dot(self.W,input.T)+np.reshape(self.b,(self.b.shape[0],1));     
        #applies non linear activation function over computed linear transformation
        self.output=self.activation(linout).T;                 
        return self.output;

&lt;/pre&gt;

&lt;p&gt;A class MLP  encapsulates all the methods for prediction,classification,training,forward and back propagation,saving and loading models etc.
Below 3 important functions are displayed.The learn function is called at every optimizer loop.
This calls the forward and backward iteration methods and updated the parameters of each hidden layer&lt;/p&gt;

&lt;p&gt;the forward iteration simply computes the output of network and while propagate_backward fuctions
is responsible for passing suitable inputs and weights to each hidden layer so that it can execute the backward algorithm loop&lt;/p&gt;

&lt;pre class=&quot;brush : python &quot;&gt;

               
   def propagate_backward(self,error,weights,input):                 
        &quot;&quot;&quot; the function that executes the backward propagation loop on hidden layers
                
        Parameters 
        ----------------
        error : numpy array,shape=(n_out,)
                average prediction error over all the input samples in output layer
                :math:`\\begin{align}\frac{\partial L  }{\partial \mathbf{a}\_{k,i}} \\end{align}`


        weight : numpy array,shape=(n_out,n_hidden)        
                 parameter weight matrix of the output layer
        
        
        input : ndarray,shape=(n_samples,n_in)
                input training data
        Returns
        ----------------
        None 
        
        &quot;&quot;&quot;              


        #input matrix for the hidden layer    
        input1=input;
        for i in range(self.n_hidden_layers):                        
            prev_error=np.inf;
            best_grad=[];
            for k in range(1):
                &quot;&quot;&quot; computing the derivative of the parameters of the hidden layers&quot;&quot;&quot;
                hidden_layer=self.hiddenLayer[self.n_hidden_layers-i-1];
                hidden_layer.compute(input1);
          
                # computing the gradient of likelyhood function wrt the parameters of the hidden layer 
                grad=hidden_layer.cost_gradients(weights,input1,error);
                #update the parameter of hidden layer
                res=self.update(hidden_layer.params,grad.flatten(),0.13);
            
                &quot;&quot;&quot; update the parameters &quot;&quot;&quot;
                hidden_layer.update_parameters(res);
            #set the weights ,inputs and error required for the back propagation algorithm
            #for the next layer
            weights=hidden_layer.W;
            error=grad[:,hidden_layer.n_in];                                    
            self.hiddenLayer[self.n_hidden_layers-i-1]=hidden_layer;
            input1=hidden_layer.output;

   def propagate_forward(self,input):
       &quot;&quot;&quot;the function that performs forward iteration to compute the output
        
       Parameters
       -----------
       input : ndarray,shape=(n_samples,n_in)
               input training data
       
       &quot;&quot;&quot;
       self.predict(input)

                
  
   def learn(self,update):
        &quot;&quot;&quot; the main function that performs learning,computing gradients and updating parameters 
            this is called by the optimizer module for each iteration
        
        Parameters
        ----------
        update - python function
                 this represents the update function that performs the gradient descent iteration
        &quot;&quot;&quot;
        #set the training data
        x,y=self.args;
        #set the update function
        self.update=update;                        
        #execute the forward iteration loop
        self.propagate_forward(x)  
        #set the input for output layer
        args1=(self.hidden_output,y);
        #set the input for the output logistic regression layer
        self.logRegressionLayer.set_training_data(args1);
        #gradient computation and parameter updation of output layer
        [params,grad]=self.logRegressionLayer.learn(update);
        self.logRegressionLayer.update_params(params);
       
        #initialize the gradiients and weights for backward error propagation
        error=grad;
        weights=self.logRegressionLayer.W;
        
        #perform the backward iteration over the hidden layers
        if self.n_hidden_layers &gt;0:   
             weights=self.logRegressionLayer.W;
             self.propagate_backward(error,weights,x)
             
        return [None,None];                        
&lt;/pre&gt;

&lt;h3&gt;Selecting the parameters of the model&lt;/h3&gt;

&lt;p&gt;As mentioned earlier that MLP consits of input,hidden and output layers.There is not fixed rule to determine the number of hidden units.The parameters are application specific and best parameters are often arrived at by emperical testing process.Less number of hidden units leads to increased generalization and training error while having a large number of training units leads to issues of with training of large number of parameters and significantly large training time.&lt;/p&gt;

&lt;h3&gt;Issues with MLP&lt;/h3&gt;

&lt;p&gt;One of the issues observed in MLP training is the slow nature of learning.The below figure illustrates the nature of learning process when a small learning parameter or improper regularization constant is chosen.Various adaptive methods can be implemented which can improve the performance ,but slow convergence and large learning times is an issue with Neural networks based learning algorithms.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://googledrive.com/host/0B-pfqaQBbAAtbExWN0Zya3JySzA/save.png&quot; alt=&quot;enter image description here&quot;&gt;&lt;/p&gt;

&lt;h3&gt;Code&lt;/h3&gt;

&lt;p&gt;The important files related to MLP are&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;MLP.py&lt;/li&gt;
&lt;li&gt;LogisticRegression.py&lt;/li&gt;
&lt;li&gt; Optimizer.py&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;The latest version of the code can be found in github repository &lt;a href=&quot;https://www.github.com/pi19404/pyVision&quot;&gt;www.github.com/pi19404/pyVision&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;The files used in the current article can be downloaded from below link
 - &lt;a href=&quot;https://github.com/pi19404/pyVision/archive/pyVision_alpha0.002.zip&quot;&gt;Github Release&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;The dataset and model file can be found under the models and data repository&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;MLP.pyvision - model file&lt;/li&gt;
&lt;li&gt;mnist.pkl.gz - data file&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;make suitable changes to the path in MLP.py file before running the code.&lt;/p&gt;
</content>
 </entry>
 
 <entry>
   <title>Jekyll A Static Website Generator</title>
   <link href="pi19404.github.io/2014/10/03/Jekyll/"/>
   <updated>2014-10-03T00:00:00+05:30</updated>
   <id>pi19404.github.io/2014/10/03/Jekyll</id>
   <content type="html">&lt;h2&gt;Introduction&lt;/h2&gt;

&lt;p&gt;In this article we will look at &lt;strong&gt;Jekyll&lt;/strong&gt; static site generator to generate a static website and host the same on &lt;strong&gt;github&lt;/strong&gt;  using github pages.&lt;/p&gt;

&lt;h2&gt;Background&lt;/h2&gt;

&lt;p&gt;Jekyll is a simple, blog aware, static site generator. &lt;/p&gt;

&lt;p&gt;A static site generator is a utility that generates ready-to-publish static HTML pages  from a set of files usually in markdown or HTML which are suitable for deployment directory on any web-server .The blog-aware means that it can support and maintain website with content added in series like that of blogs.&lt;/p&gt;

&lt;p&gt;Jekyll is the engine behind GitHub Pages, which enables us to use Jekyll to host  the project’s page, blog, or website from GitHub’s servers for free&lt;/p&gt;

&lt;h2&gt;Github Pages and Jekyll Installation&lt;/h2&gt;

&lt;p&gt;Let us consider the github project &lt;a href=&quot;https://github.com/pi19404/pyVision&quot;&gt;www.github.com/pi19404/pyVision.&lt;/a&gt; &lt;/p&gt;

&lt;p&gt;Github pages generator gives us the facility to create a website for the project using one of the standard defined themes .This is the easiest way to start a project without having to worry about the HTML themes and CSS files etc and just focus on content writing.&lt;/p&gt;

&lt;p&gt;To generate a static webpage of the project go to project settings on github.com
&lt;img src=&quot;https://googledrive.com/host/0B-pfqaQBbAAtbExWN0Zya3JySzA/ss5.png&quot; alt=&quot;enter image description here&quot;&gt;
Click on the &lt;strong&gt;&lt;em&gt;Automatic page generator&lt;/em&gt;&lt;/strong&gt; options&lt;/p&gt;

&lt;p&gt;This will provide you with a markdown editor where you can enter the contents for the main page of the website.&lt;/p&gt;

&lt;p&gt;Enter the name ,content and other details and click on &lt;strong&gt;&lt;em&gt;&amp;quot;Continue to Layouts Button&amp;quot;&lt;/em&gt;&lt;/strong&gt; to proceed to HTML theme selection
&lt;img src=&quot;https://googledrive.com/host/0B-pfqaQBbAAtbExWN0Zya3JySzA/ss6.png&quot; alt=&quot;enter image description here&quot;&gt;
Select the desired theme and click on &lt;strong&gt;&lt;em&gt;&amp;quot;Publish Page&amp;quot;&lt;/em&gt;&lt;/strong&gt; button to complete the process
&lt;img src=&quot;https://googledrive.com/host/0B-pfqaQBbAAtbExWN0Zya3JySzA/ss7.png&quot; alt=&quot;enter image description here&quot;&gt;
This will lead to github servers hosting the created website on &amp;quot;http://pi19404.github.io/pyVision&amp;quot;&lt;/p&gt;

&lt;p&gt;now we are ready to modify and edit the website.The sources of the website are also stored in github repository of the  project in the gh-pages branch.&lt;/p&gt;

&lt;p&gt;Thus all we have to do to access the sources is to checkout the gh-pages branch and start modifying content on local server and then push changes onto remote github repository.The github servers will regenerated the website and latest changes will be reflected on your website.&lt;/p&gt;

&lt;p&gt;The same process can be used to maintain blogs,post or any other content of the website.&lt;/p&gt;

&lt;p&gt;Every GitHub Page is run through Jekyll when you push content to gh-pages branch within your repository&lt;/p&gt;

&lt;h2&gt;Installing Jekyll&lt;/h2&gt;

&lt;p&gt;Though Jekyll installation on local PC is not necessary.It can be installed in order to preview the website  and troubleshoot issues or bugs before pushing the site on GitHub Pages.&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;p&gt;Ruby - Jekyll requires the Ruby version 1.9.3 or higher.&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;To install ruby easiest way is to download ruby install managers like &lt;strong&gt;&lt;em&gt;&amp;quot;rvm - The Ruby Version Manager&amp;quot;&lt;/em&gt;&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;Detailed installation instruction for &lt;code&gt;rvm&lt;/code&gt; can be found at &lt;a href=&quot;http://rvm.io/rvm/install&quot;&gt;http://rvm.io/rvm/install&lt;/a&gt;  or install the software from package manager like synaptic&lt;/li&gt;
&lt;li&gt;To install Ruby : &lt;code&gt;rvm install 1.9.3&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;This will download the ruby 1.9.3 sources and perform compilation and deployment  at &amp;quot;/usr/share/ruby-rvm/&amp;quot;&lt;/li&gt;
&lt;li&gt;In some cases you many encounter compilation issues due to outdated version of OpenSSL,in which case install the openssl from rvm tool : &lt;code&gt;rvm pkg install openssl&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;This will install the openssl packaged within the rvm installation directory&lt;/li&gt;
&lt;li&gt;&lt;p&gt;While compiling ruby we can given commandline arguments so that it referes the openSSL package from the rvm install directory and not default system path :&lt;/p&gt;

&lt;p&gt;&lt;code&gt;rvm install 1.9.3 --with-openssl-dir=/usr/share/ruby-rvm/usr&lt;/code&gt; &lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Bundler - Bundler is a package manager ,This can be installed as easily&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;gem install bundler&lt;/strong&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Jekyll installation&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Clone the sites repository on the local machine&lt;/li&gt;
&lt;li&gt;Change the branch to gh-pages if you have created a project website&lt;/li&gt;
&lt;li&gt;Create a file called GemFile in the directory with the following content&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;pre class=&quot;brush : html &quot;&gt;
                 source 'https://rubygems.org'
                 gem 'github-pages'
&lt;/pre&gt;
&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-text&quot; data-lang=&quot;text&quot;&gt; - Run the command : `bundle install` for installing Jekyll
 - To ensure that local development environment is same as that of github regularily update the local environment 

   `bundle update github-pages `
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;ul&gt;
&lt;li&gt;Running Jekyll : &lt;code&gt;bundle exec jekyll serve&lt;/code&gt;
The website is accessible for preview at : http://localhost:4000&lt;/li&gt;
&lt;/ul&gt;

&lt;h2&gt;Layouts and Website Template&lt;/h2&gt;

&lt;p&gt;Front-matter is just a set of metadata, delineated by three dashes which takes for form of valid YAML content.Any file that contains a front matter block will be processed by Jekyll as a special file.
Thus .Jekyll requires that Markdown files have front-matter defined at the top of every file.The front matter can be included in top of markdown or HTML files.&lt;/p&gt;

&lt;p&gt;Between the dashed lines you can set predefined variables ( title,layout) or set custom used defined variables.&lt;/p&gt;

&lt;p&gt;The present article was written using Markdown syntax and frontmatter included on top of the files was&lt;/p&gt;

&lt;pre class=&quot;brush : html &quot;&gt;
---
layout: post
title: Jekyll A Static Website Generator
---
Introduction
-------------
In this article we will look at **Jekyll** static site generator to generate a static website and host the same on **github**  using github pages.
&lt;/pre&gt;

&lt;p&gt;The layout tag specifies the template to be used for generating posts.The templates can be makrdown containing HTML contents.&lt;/p&gt;

&lt;p&gt;Jekyll uses the &lt;a href=&quot;https://github.com/shopify/liquid/wiki/liquid-for-designers&quot;&gt;Liquid template system&lt;/a&gt; .The variables defined in front matter and page contents can be accessed  accessed using the Liquid tags both within the files as well as any layouts that page of post relies on.&lt;/p&gt;

&lt;p&gt;Let us look at the template for post called &lt;strong&gt;post.html&lt;/strong&gt; and how contents are incorporated using Liquid markup language&lt;/p&gt;

&lt;h2&gt;&lt;pre class=&quot;brush : html &quot;&gt;&lt;/h2&gt;

&lt;h2&gt;layout: default&lt;/h2&gt;

&lt;p&gt;&lt;article class=&quot;post&quot;&gt;&lt;/p&gt;

&lt;p&gt;&lt;h1&gt;{{  page.title }}&lt;/h1&gt;&lt;/p&gt;

&lt;p&gt;&lt;div class=&quot;entry&quot;&gt;
    {{  content }}&amp;#39;
  &lt;/div&gt;&lt;/p&gt;

&lt;p&gt;&lt;div class=&quot;date&quot;&gt;
    Written on {{  page.date | date: &amp;quot;%B %e, %Y&amp;quot; }}
  &lt;/div&gt;&lt;/p&gt;

&lt;p&gt;&lt;/article&gt;
&lt;/pre&gt;&lt;/p&gt;

&lt;p&gt;Thus when a post is created using the template,then the title specified in the frontmatter is the post is accessed via variable page.title.The page content is accessed via variable content.
Jekyll provides numerous  predefined global variables that you can set in the front matter of a page or post.&lt;/p&gt;

&lt;p&gt;Information on some of them can be found at &lt;a href=&quot;http://jekyllrb.com/docs/frontmatter/#predefined-global-variables&quot;&gt;Frontmatter Predefined variables&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;The rendered html output for above file is &lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://googledrive.com/host/0B-pfqaQBbAAtbExWN0Zya3JySzA/ss8.png&quot; alt=&quot;enter link description here&quot;&gt;&lt;/p&gt;

&lt;p&gt;we have seen that in &lt;strong&gt;post.html&lt;/strong&gt; file we have included frontmatter &lt;strong&gt;&amp;quot;layout&amp;quot;&lt;/strong&gt;.This enables us to include the contents of the post.html file into another files as its contents using Liquid markup language.&lt;/p&gt;

&lt;p&gt;This enables us to maintain layout and content files separately and we can change the site layout whenever required without making any changes to the content files.The frontmatter predefined variable provides a lot of flexibility in how we can define complex layouts and themes for the website.&lt;/p&gt;

&lt;p&gt;There is a &lt;strong&gt;index.html&lt;/strong&gt; file in the project repository that is auto generated by github pages.
We modify this file so that it can be used as a base template for all the pages on the website.&lt;/p&gt;

&lt;p&gt;we create a &lt;code&gt;_layouts&lt;/code&gt; directory in the root folder of the repository.This directory contains all the files that can be accessed by defining the &lt;code&gt;layout&lt;/code&gt; variable in the frontmatter of the files.If the layout variable is assigned values post then the file post.html in the _layout directory will be accessed.&lt;/p&gt;

&lt;p&gt;we create a file default.html.The default.html file contains the html headers,javascript,stylesheets etc as well as contents to be included in header and footer of pages. Again Liquid markup language is used to specify where the content is be be included&lt;/p&gt;

&lt;pre class=&quot;brush : html &quot;&gt;
&lt;html&gt;
  &lt;head&gt;
    &lt;meta charset=&quot;utf-8&quot;&gt;
    &lt;meta http-equiv=&quot;X-UA-Compatible&quot; content=&quot;chrome=1&quot;&gt;
    &lt;title&gt;pyVision by pi19404&lt;/title&gt;

    &lt;link rel=&quot;stylesheet&quot; href=&quot;/stylesheets/styles.css&quot;&gt;
    &lt;link rel=&quot;stylesheet&quot; href=&quot;/stylesheets/pygment_trac.css&quot;&gt;
    &lt;script src=&quot;javascripts/scale.fix.js&quot;&gt;&lt;/script&gt;
    &lt;meta name=&quot;viewport&quot; content=&quot;width=device-width, initial-scale=1, user-scalable=no&quot;&gt;

 
  &lt;/head&gt;
  &lt;body&gt;
    &lt;div class=&quot;wrapper&quot;&gt;
      &lt;header&gt;
         ........ 
      &lt;/header&gt;
      &lt;section&gt;
        {{  content }}  &lt;!-----  contents inserted here ---&gt;
      &lt;/section&gt;
    &lt;/div&gt;
    &lt;footer&gt;
      .......
    &lt;/footer&gt;
    
    
  &lt;/body&gt;
&lt;/html&gt;
&lt;/pre&gt;

&lt;p&gt;If the file is markdown file then all its contents are inserted in place of contents tag.If the file is HTML then the declaration inside section tag of class content is inserted in place of contents tag.All the pages of the website including the main page index.html contains frontmatter are designed so that generated contents are inserted within default layout.&lt;/p&gt;

&lt;h2&gt;Posting Blog&lt;/h2&gt;

&lt;p&gt;All the blog posts reside in the &lt;code&gt;_posts&lt;/code&gt; directory.The format of filename is &lt;strong&gt;year-month-day-title.ext&lt;/strong&gt;.This will generate the blogs posts in year/month/day directory of static website.
The blog posts can be html or markdown .&lt;/p&gt;

&lt;p&gt;Let us create a blog post called 2014-10-03-Jekyll.md&lt;/p&gt;

&lt;pre class=&quot;brush : html &quot;&gt;
---
layout: post
title: Jekyll A Static Website Generator
---

Introduction
-------------
In this article we will look at **Jekyll** static site generator to generate a static website and host the same on **github**  using github pages.
..........
&lt;/pre&gt;

&lt;p&gt;Now we need to provide links to access the blog content from the main page of website.This is done using Jekyll variables and adding the below content in the &lt;strong&gt;index.html&lt;/strong&gt; page&lt;/p&gt;

&lt;pre class=&quot;brush : html &quot;&gt;
---
layout: default
---
&lt;section class=&quot;content&quot;&gt;
      &lt;section&gt;
        .......
      &lt;/section&gt;

&lt;ul class=&quot;entries&quot;&gt;
  &lt;li&gt; Blog Posts -{{  site.url }}&lt;/li&gt;
  {{%  for post in site.posts %}}

  &lt;li&gt;
    &lt;a href=&quot;{{&quot;&gt;      
      &lt;h3&gt;{{ post.title }}&lt;/h3&gt;
    &lt;/a&gt;
  &lt;/li&gt;
 
  {{%  endfor %}}
&lt;/ul&gt;

&lt;/section&gt;
&lt;/pre&gt;

&lt;p&gt;now we launch the website on local machine by executing command &lt;/p&gt;

&lt;p&gt;&lt;code&gt;bundle exec jekyll serve&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://googledrive.com/host/0B-pfqaQBbAAtbExWN0Zya3JySzA/ss9.png&quot; alt=&quot;enter image description here&quot;&gt;&lt;/p&gt;

&lt;p&gt;now we push the repository onto github &lt;/p&gt;

&lt;p&gt;&lt;code&gt;git push origin gh-pages&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;access the webpage and observe the similar output as on local server &lt;/p&gt;

&lt;p&gt;The markdown used is called &lt;code&gt;GitHub Flavored Markdown&lt;/code&gt;,It is different from standard markdown language.The following like gives the difference and highlights the features of &lt;a href=&quot;https://help.github.com/articles/github-flavored-markdown/&quot;&gt;Github Flavored markdown&lt;/a&gt; language&lt;/p&gt;

&lt;p&gt;now that we have created the html,say we want to use the html content on other sites like codeproject or blogger.we can access the html at _site/posts/2013/10/03/Jekyll.html.&lt;/p&gt;

&lt;p&gt;we can copy the relevant sections of html file and with slight modifications make it compatible with other websites.&lt;/p&gt;

&lt;h2&gt;Code&lt;/h2&gt;

&lt;p&gt;The pyVision repository can be found at &lt;code&gt;[www.github.com/pi19404/pyvision](www.github.com/pi19404/pyvision)&lt;/code&gt; and website can be seen at &lt;a href=&quot;http://pi19404.github.io/pyVision/&quot;&gt;pyvision&lt;/a&gt;
All the files used in the preset article can be found in the gh-pages branch of the repository.&lt;/p&gt;

&lt;p&gt;The file for the present article can be found at &lt;strong&gt;_posts/2014-10-03-Jekyll.md&lt;/strong&gt;
The source files in &lt;code&gt;gh-pages branch&lt;/code&gt; of the repository files can also be downloaded from  &lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&quot;http://www.codeproject.com/KB/Articles/826515/pyVision.rar&quot;&gt;Download pyVision.rar&lt;/a&gt; - 1.5 MB&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;http://www.codeproject.com/KB/Articles/826515/pyVision.zip&quot;&gt;Download pyVision.zip&lt;/a&gt; - 1.6 MB&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;https://github.com/pi19404/pyVision/releases/download/pyVision/pyVision_ghpages.rar&quot;&gt;Alternate link&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
</content>
 </entry>
 

</feed>
