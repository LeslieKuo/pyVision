---
layout: post
title: Natural Language Understanding - Intent Detection with Keras and MLP
published: false
---

In this example we will look at the problem of natural language understanding.The aim is simply to understand the meaning of sentense. This is a unsolved problem in the context of open domain sentense understaing ie there exists no system that can understand the meaning of any open domain sentense.However many of the techniques that work well do so within a specific domain.

An intent is a group of utterances with similar meaning

Airline Travel Information System (ATIS) dataset is a standard data set used to demonstrate
and benchmark various NLU algorithms.ATIS consists of spoken queries on flight related information

we will use modified version of the ATIS dataset used in the project [https://github.com/yvchen/JointSLU](https://github.com/yvchen/JointSLU/tree/master/data) . This database contains spoken queries,associated intents and entities in the statements.

The dataset consists of sentenses labelled/encoded in Inside Outside Beginning (IOB) representation.

An example utterance is 


|Show |flights	|from	|Boston	|to	|New |York |today | EOS |
|O |O |O	|B-dept	|O	|B-arr	|I-arr	|B-date | atis_flight |


The aim would be to first understand the intent of the statement,which in the above examples is to show flight information (atis_flight ) .The second operation is to understand that source city is boston,departure city is new york, and date and time is specified by today.Second operation is called as slot filling . 

First task is to read the ATIS dataset

```
def processCSVData(filename):
    output=[]
    lables=[]
    with open(filename, 'r') as f:
        for rowx in f:
            r={}
            words = rowx.split()
            intent_name=words[len( words)-1]
            words=words[0:len( words)-1]
            aa="";
            cc="";
            state=-1
            for w in words:
                if w=="EOS":
                    state=1;

                if state==0:
                    aa=aa+" "+w;
                if state==1:
                    cc=cc+" "+w
                if w=="BOS":
                    state=0

            r['text']=aa
            r['tags'] =cc
            r['intent']=intent_name
            lables.append(intent_name)
            output.append(r)
    lables=np.unique(lables)
    return output,lables

output,lables=processCSVData("atis.txt")
#print output[0],lables
print "number of samples",len(output)
print "number of intent",len(lables)

```        


The ATIS official split contains 4,978/893 sentences and intent 22 classes.

Our first task would be to just perform intent detection. The input to the classifier is a sequence
of words and output is the intent associated with the statement.

We will be first represent each sentense in the training data as a vector.We will be using spacy document vector representation to represent each sentense as a 300 dimensional vector which is obtained by averaging over word vector embeddings of all the words contained in the sentense.


Below is code for feature extraction

```
def docVector(tokens):
		nlp1 = spacy.load('en')
        k=tokens
        sentence1 = ''.join([i if ord(i) < 128 else ' ' for i in k['text']])
        r = unicode(sentence1)
        doc=nlp1(r)
        tokens['feature']=doc.vector;
        return tokens


def convertlables2vectors(Ytrain):
    label_encoder = preprocessing.LabelEncoder()
    label_encoder.fit(Ytrain)
    Ytrain = label_encoder.transform(Ytrain)
    Ytrain = keras.utils.to_categorical(Ytrain)
    return Ytrain


output=processCSVData("atis.txt")


Xtrain=[];
Ytrain=[];

index=0
for k in output:
    print "processing records ",index
    index=index+1
    k1 = docVector(k,nlp1)
    Xtrain.append(k1['feature'])
    Ytrain.append(k1['intent'])

```            

we will train the Neural network for which takes as input feature vector representing the document and output lable is the intent detected

```
print("Training data: ")
print(Xtrain.shape), (Ytrain.shape)
model=create_model(Xtrain.shape[1],Ytrain.shape[1])
model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])
model.fit(Xtrain,Ytrain,epochs=20, batch_size=100, verbose=1)
save_model(model,"/tmp/model6")

```

[rasa NLU](https://nlu.rasa.ai/) is an open source tool for intent classification and entity extraction. 
It uses similar approach for intent detection.

**References**

- https://nlu.rasa.ai/